{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543224b5-768e-4e45-b9a6-83b4572f617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the batch size:  64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 64\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pickle\n",
    "import mmap\n",
    "import random\n",
    "# import onnxruntime as ort\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description='This is a demonstration program')\n",
    "\n",
    "# Add an argument for batch_size\n",
    "parser.add_argument('-batch_size', type=str, required=True, help='Please provide a batch size')\n",
    "\n",
    "# Check if running in a Jupyter Notebook\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    # Prompt the user for batch size interactively\n",
    "    batch_size = input(\"Please enter the batch size: \")\n",
    "    args = argparse.Namespace(batch_size=batch_size)  # Simulate parsed arguments\n",
    "else:\n",
    "    # Parse arguments normally when running as a standalone script\n",
    "    args = parser.parse_args()\n",
    "# Print the argument\n",
    "print(f'batch size: {args.batch_size}')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f66812-f694-4759-9ffb-ccb29b8ebd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x7f', '\\x80', '\\x81', '\\x82', '\\x83', '\\x84', '\\x86', '\\x87', '\\x88', '\\x89', '\\x8a', '\\x8b', '\\x8c', '\\x8d', '\\x8e', '\\x8f', '\\x90', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97', '\\x98', '\\x99', '\\x9a', '\\x9b', '\\x9c', '\\x9d', '\\x9e', '\\x9f', '¡', '¢', '£', '¤', '¥', '¦', '§', '¨', '©', 'ª', '«', '¬', '\\xad', '®', '¯', '°', '±', '²', '³', '´', 'µ', '¶', '·', '¸', '¹', 'º', '»', '¼', '½', '¾', '¿', 'À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Æ', 'Ç', 'È', 'É', 'Ê', 'Ë', 'Ì', 'Í', 'Î', 'Ï', 'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Õ', 'Ö', '×', 'Ø', 'Ù', 'Ú', 'Û', 'Ü', 'Ý', 'Þ', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', '÷', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'þ', 'ÿ', 'Ā', 'ā', 'Ă', 'ă', 'Ą', 'ą', 'Ć', 'ć', 'Ĉ', 'ĉ', 'Ċ', 'ċ', 'Č', 'č', 'Ď', 'ď', 'Đ', 'đ', 'Ē', 'ē', 'Ĕ', 'ĕ', 'Ė', 'ė', 'Ę', 'ę', 'Ě', 'ě', 'Ĝ', 'ĝ', 'Ğ', 'ğ', 'Ġ', 'ġ', 'Ģ', 'ģ', 'Ĥ', 'ĥ', 'Ħ', 'ħ', 'Ĩ', 'ĩ', 'Ī', 'ī', 'Ĭ', 'ĭ', 'Į', 'į', 'İ', 'ı', 'Ĳ', 'ĳ', 'Ĵ', 'ĵ', 'Ķ', 'ķ', 'ĸ', 'Ĺ', 'ĺ', 'Ļ', 'ļ', 'Ľ', 'ľ', 'Ŀ', 'ŀ', 'Ł', 'ł', 'Ń', 'ń', 'Ņ', 'ņ', 'Ň', 'ň', 'Ŋ', 'ŋ', 'Ō', 'ō', 'Ŏ', 'ŏ', 'Ő', 'ő', 'Œ', 'œ', 'Ŕ', 'ŕ', 'Ŗ', 'ŗ', 'Ř', 'ř', 'Ś', 'ś', 'Ŝ', 'ŝ', 'Ş', 'ş', 'Š', 'š', 'Ţ', 'ţ', 'Ť', 'ť', 'Ŧ', 'ŧ', 'Ũ', 'ũ', 'Ū', 'ū', 'Ŭ', 'ŭ', 'Ů', 'ů', 'Ű', 'ű', 'Ų', 'ų', 'Ŵ', 'ŵ', 'Ŷ', 'ŷ', 'Ÿ', 'Ź', 'ź', 'Ż', 'ż', 'Ž', 'ž', 'ſ', 'ƀ', 'Ɓ', 'Ƃ', 'ƃ', 'Ɔ', 'Ƈ', 'ƈ', 'Ɖ', 'Ɗ', 'Ƌ', 'ƌ', 'ƍ', 'Ǝ', 'Ə', 'Ɛ', 'Ƒ', 'ƒ', 'Ɠ', 'Ɣ', 'ƕ', 'Ɩ', 'Ɨ', 'Ƙ', 'ƙ', 'ƚ', 'ƛ', 'Ɯ', 'Ɲ', 'ƞ', 'Ơ', 'ơ', 'Ƣ', 'ƣ', 'Ƥ', 'ƥ', 'Ʀ', 'Ʃ', 'ƪ', 'ƫ', 'Ƭ', 'ƭ', 'Ʈ', 'Ư', 'ư', 'Ʊ', 'Ʋ', 'Ƴ', 'ƴ', 'Ƶ', 'ƶ', 'Ʒ', 'Ƹ', 'ƹ', 'ƺ', 'ƾ', 'ƿ', 'ǀ', 'ǁ', 'ǂ', 'ǃ', 'Ǆ', 'ǅ', 'ǆ', 'Ǉ', 'ǈ', 'ǉ', 'Ǌ', 'ǋ', 'ǌ', 'Ǎ', 'ǎ', 'Ǐ', 'ǐ', 'Ǒ', 'ǒ', 'Ǔ', 'ǔ', 'Ǖ', 'ǖ', 'Ǘ', 'ǘ', 'Ǚ', 'ǚ', 'Ǜ', 'ǜ', 'ǝ', 'Ǟ', 'ǟ', 'Ǡ', 'ǡ', 'Ǣ', 'ǣ', 'Ǥ', 'ǥ', 'Ǧ', 'ǧ', 'Ǩ', 'ǩ', 'Ǫ', 'ǫ', 'Ǭ', 'ǭ', 'Ǯ', 'ǯ', 'ǰ', 'Ǳ', 'ǲ', 'ǳ', 'Ǵ', 'ǵ', 'Ƿ', 'Ǹ', 'ǹ', 'Ǻ', 'ǻ', 'Ǽ', 'ǽ', 'Ǿ', 'ǿ', 'Ȁ', 'ȁ', 'Ȃ', 'ȃ', 'Ȅ', 'ȅ', 'Ȇ', 'ȇ', 'Ȉ', 'ȉ', 'Ȋ', 'ȋ', 'Ȍ', 'ȍ', 'Ȏ', 'ȏ', 'Ȑ', 'ȑ', 'Ȓ', 'ȓ', 'Ȕ', 'ȕ', 'Ȗ', 'ȗ', 'Ș', 'ș', 'Ț', 'ț', 'Ȝ', 'ȝ', 'Ȟ', 'ȟ', 'Ƞ', 'ȡ', 'Ȥ', 'ȥ', 'Ȧ', 'ȧ', 'Ȩ', 'ȩ', 'Ȫ', 'ȫ', 'Ȭ', 'ȭ', 'Ȯ', 'ȯ', 'Ȱ', 'ȱ', 'Ȳ', 'ȳ', 'ȴ', 'ȵ', 'ȶ', 'ȷ', 'Ⱥ', 'Ȼ', 'ȼ', 'Ƚ', 'Ⱦ', 'ɀ', 'Ƀ', 'Ɉ', 'Ɍ', 'Ɏ', 'ɐ', 'ɑ', 'ɒ', 'ɓ', 'ɔ', 'ɕ', 'ɖ', 'ɗ', 'ɘ', 'ə', 'ɚ', 'ɛ', 'ɜ', 'ɝ', 'ɞ', 'ɟ', 'ɠ', 'ɡ', 'ɢ', 'ɣ', 'ɤ', 'ɥ', 'ɦ', 'ɧ', 'ɨ', 'ɩ', 'ɪ', 'ɫ', 'ɬ', 'ɭ', 'ɮ', 'ɯ', 'ɰ', 'ɱ', 'ɲ', 'ɳ', 'ɴ', 'ɵ', 'ɶ', 'ɸ', 'ɹ', 'ɺ', 'ɻ', 'ɼ', 'ɽ', 'ɾ', 'ɿ', 'ʀ', 'ʁ', 'ʂ', 'ʃ', 'ʄ', 'ʅ', 'ʆ', 'ʇ', 'ʈ', 'ʉ', 'ʊ', 'ʋ', 'ʌ', 'ʍ', 'ʎ', 'ʏ', 'ʐ', 'ʑ', 'ʒ', 'ʓ', 'ʔ', 'ʕ', 'ʖ', 'ʘ', 'ʙ', 'ʚ', 'ʛ', 'ʜ', 'ʝ', 'ʞ', 'ʟ', 'ʠ', 'ʣ', 'ʤ', 'ʥ', 'ʦ', 'ʧ', 'ʨ', 'ʩ', 'ʪ', 'ʫ', 'ʰ', 'ʲ', 'ʳ', 'ʷ', 'ʹ', 'ʺ', 'ʻ', 'ʼ', 'ʽ', 'ʾ', 'ʿ', 'ˀ', '˃', 'ˆ', 'ˇ', 'ˈ', 'ˊ', 'ˋ', 'ˌ', 'ː', 'ˑ', '˘', '˙', '˚', '˛', '˜', '˝', '˞', 'ˠ', 'ˡ', 'ˢ', 'ˣ', 'ˤ', '˥', '˦', '˧', '˨', '˩', 'ˮ', '̀', '́', '̂', '̃', '̄', '̅', '̆', '̇', '̈', '̊', '̌', '̍', '̐', '̑', '̓', '̕', '̖', '̗', '̘', '̙', '̚', '̛', '̜', '̝', '̞', '̟', '̠', '̡', '̢', '̣', '̤', '̥', '̦', '̧', '̨', '̩', '̪', '̫', '̬', '̭', '̮', '̯', '̰', '̱', '̲', '̳', '̵', '̶', '̷', '̸', '̹', '̺', '̻', '̼', '̾', '̿', '̀', '́', '͂', 'ͅ', '͇', '͈', '͉', '͍', '͎', '͏', '͑', '͓', '͔', '͕', '͖', '͘', '͙', '͚', '͜', '͝', '͞', '͟', '͠', '͡', '͢', 'ͼ', 'ͽ', ';', '΄', 'Ά', '·', 'Έ', 'Ί', 'Ό', 'Ώ', 'ΐ', 'Α', 'Β', 'Γ', 'Δ', 'Ε', 'Ζ', 'Η', 'Θ', 'Ι', 'Κ', 'Λ', 'Μ', 'Ν', 'Ξ', 'Ο', 'Π', 'Ρ', 'Σ', 'Τ', 'Υ', 'Φ', 'Χ', 'Ψ', 'Ω', 'ά', 'έ', 'ή', 'ί', 'α', 'β', 'γ', 'δ', 'ε', 'ζ', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ξ', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'υ', 'φ', 'χ', 'ψ', 'ω', 'ϊ', 'ϋ', 'ό', 'ύ', 'ώ', 'ϒ', 'ϕ', 'ϝ', 'ϟ', 'ϯ', 'ϵ', 'Ϲ', 'ϻ', 'Ё', 'Ђ', 'Ѓ', 'Є', 'Ѕ', 'І', 'Ј', 'Љ', 'Њ', 'Ћ', 'Ќ', 'Џ', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'ђ', 'ѓ', 'є', 'ѕ', 'і', 'ї', 'ј', 'љ', 'њ', 'ћ', 'ќ', 'ѝ', 'ў', 'џ', 'ѣ', 'Ѧ', 'ѧ', 'Ѩ', 'ѩ', 'Ѫ', 'ѫ', 'Ѭ', 'ѭ', 'ѳ', 'ѵ', 'ѹ', 'Ѻ', 'ѻ', '҉', 'Ґ', 'ґ', 'Ғ', 'ғ', 'ҕ', 'Җ', 'Қ', 'қ', 'Ҝ', 'ҟ', 'Ҡ', 'ң', 'ҧ', 'Ҩ', 'ҩ', 'Ҭ', 'ҭ', 'ү', 'ұ', 'ҳ', 'ҵ', 'ҷ', 'ҽ', 'Ҿ', 'ҿ', 'Ӄ', 'ӄ', 'Ӎ', 'ӑ', 'Ә', 'ә', 'ӡ', 'ӣ', 'Ө', 'ө', 'ӯ', 'Ԍ', 'ԛ', 'Ա', 'Բ', 'Դ', 'Ե', 'Զ', 'Ծ', 'Հ', 'Մ', 'Ս', 'Վ', 'Ց', 'Փ', 'Ք', 'ա', 'բ', 'գ', 'դ', 'ե', 'զ', 'ը', 'թ', 'ի', 'լ', 'խ', 'ծ', 'կ', 'հ', 'ղ', 'ճ', 'մ', 'յ', 'ն', 'շ', 'ո', 'չ', 'պ', 'ջ', 'ռ', 'ս', 'վ', 'տ', 'ր', 'ց', 'ւ', 'ք', 'օ', 'ֆ', 'և', '֑', '֔', '֖', '֗', '֙', '֛', '֝', '֞', '֣', '֤', '֥', '֨', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֻ', 'ּ', 'ֽ', '־', 'ׁ', 'ׂ', '׃', 'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'ך', 'כ', 'ל', 'ם', 'מ', 'ן', 'נ', 'ס', 'ע', 'ף', 'פ', 'ץ', 'צ', 'ק', 'ר', 'ש', 'ת', 'ײ', '׳', '״', '،', '؛', '؟', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ـ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', '٠', '١', '٢', '٣', '٤', '٥', '٦', '٧', '٨', '٩', '٫', '٬', '٭', 'ٰ', 'ٱ', 'ٹ', 'پ', 'چ', 'ڑ', 'ژ', 'ښ', 'ڢ', 'ک', 'ڮ', 'گ', 'ں', 'ڻ', 'ھ', 'ہ', 'ۂ', 'ۃ', 'ۆ', 'ۇ', 'ۈ', 'ۋ', 'ی', 'ێ', 'ې', 'ے', 'ە', 'ۖ', 'ۗ', 'ۚ', 'ۜ', '۞', 'ۣ', '۩', '۰', '۱', '۲', '۳', '۴', '۵', '۶', '۷', '۸', '۹', '܂', 'ܐ', 'ܒ', 'ܓ', 'ܔ', 'ܕ', 'ܘ', 'ܚ', 'ܛ', 'ܝ', 'ܟ', 'ܠ', 'ܡ', 'ܢ', 'ܣ', 'ܥ', 'ܦ', 'ܩ', 'ܪ', 'ܫ', 'ܬ', 'ܵ', 'ܸ', 'ܹ', 'ݒ', 'މ', 'ލ', 'ާ', 'ެ', 'ߊ', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ए', 'ऐ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ॐ', 'ढ़', '।', '॥', '७', 'ঁ', 'ং', 'ঃ', 'অ', 'আ', 'ই', 'উ', 'এ', 'ও', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ', 'স', 'হ', '়', 'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ', '্', 'ৎ', 'ড়', 'য়', '০', '১', '২', '৩', '৫', '৬', '৯', 'ৰ', 'ৱ', 'ਂ', 'ਅ', 'ਆ', 'ਇ', 'ਈ', 'ਉ', 'ਏ', 'ਐ', 'ਓ', 'ਕ', 'ਖ', 'ਗ', 'ਘ', 'ਚ', 'ਛ', 'ਜ', 'ਝ', 'ਟ', 'ਠ', 'ਡ', 'ਢ', 'ਣ', 'ਤ', 'ਦ', 'ਧ', 'ਨ', 'ਪ', 'ਫ', 'ਬ', 'ਭ', 'ਮ', 'ਯ', 'ਰ', 'ਲ', 'ਵ', 'ਸ', 'ਹ', '਼', 'ਾ', 'ਿ', 'ੀ', 'ੁ', 'ੂ', 'ੇ', 'ੈ', 'ੋ', 'ੌ', '੍', 'ੜ', '੨', '੩', '੪', '੭', 'ੰ', 'ੱ', 'ગ', 'જ', 'ડ', 'ત', 'ધ', 'પ', 'ફ', 'બ', 'મ', 'ર', 'લ', 'ા', 'િ', 'ી', 'ુ', 'ો', '૭', 'ଉ', 'ଓ', 'କ', 'ଡ', 'ତ', 'ଦ', 'ବ', 'ଳ', 'ଶ', 'ସ', '଼', 'ା', 'ି', '୍', 'அ', 'ஆ', 'இ', 'எ', 'ஏ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஜ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', '்', 'ం', 'అ', 'క', 'గ', 'చ', 'జ', 'ట', 'డ', 'త', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'మ', 'య', 'ర', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ు', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', '్', '౪', 'ಂ', 'ಎ', 'ಕ', 'ಗ', 'ಜ', 'ಠ', 'ಡ', 'ತ', 'ಥ', 'ದ', 'ನ', 'ಪ', 'ಫ', 'ಬ', 'ಮ', 'ಯ', 'ರ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಸ', 'ಾ', 'ಿ', 'ು', 'ೂ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', '್', 'ം', 'ങ', 'ട', 'ത', 'ന', 'പ', 'മ', 'യ', 'ര', 'ല', 'ള', 'വ', 'ശ', 'ഷ', 'ാ', 'ി', 'ീ', 'െ', 'ൈ', 'ോ', '്', 'ൻ', 'ർ', 'ං', 'එ', 'ක', 'ග', 'ට', 'ඩ', 'ණ', 'ත', 'ද', 'න', 'ඳ', 'බ', 'ම', 'ය', 'ර', 'ල', 'ව', 'ශ', 'ස', 'හ', 'ෆ', '්', 'ා', 'ි', 'ු', 'ෙ', 'ේ', 'ෛ', 'ො', '෴', 'ก', 'ข', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', '฿', 'เ', 'แ', 'โ', 'ใ', 'ไ', 'ๆ', '็', '่', '้', '๊', '๋', '์', '๏', '๑', '๒', '๓', '๖', '๘', '๛', 'ກ', 'ຂ', 'ງ', 'ຈ', 'ຊ', 'ຍ', 'ດ', 'ຕ', 'ຖ', 'ທ', 'ບ', 'ປ', 'ພ', 'ມ', 'ລ', 'ວ', 'ສ', 'ຫ', 'ອ', 'ະ', 'າ', 'ີ', 'ຶ', 'ຸ', 'ູ', 'ົ', 'ຽ', 'ເ', 'ແ', '່', '້', 'ໍ', '໒', 'ໜ', '༄', '༅', '༆', '་', '།', '༎', '༐', '༒', '༼', '༽', 'ཀ', 'ཁ', 'ག', 'ང', 'ཅ', 'ཆ', 'ཇ', 'ཉ', 'ཏ', 'ཐ', 'ད', 'ན', 'པ', 'ཕ', 'བ', 'མ', 'ཙ', 'ཚ', 'ཛ', 'ཞ', 'ཟ', 'འ', 'ཡ', 'ར', 'ལ', 'ཤ', 'ས', 'ཨ', 'ི', 'ུ', 'ེ', 'ོ', 'ཾ', 'ྐ', 'ྒ', 'ྔ', 'ྕ', 'ྗ', 'ྙ', 'ྟ', 'ྡ', 'ྣ', 'ྤ', 'ྦ', 'ྨ', 'ྩ', 'ྭ', 'ྱ', 'ྲ', 'ླ', 'ྷ', '࿕', '࿖', '࿗', '࿘', 'က', 'ခ', 'င', 'စ', 'ဆ', 'ဇ', 'တ', 'ထ', 'ဒ', 'န', 'ပ', 'မ', 'ရ', 'လ', 'ဝ', 'သ', 'ဟ', 'ဤ', 'ာ', 'ိ', 'ီ', 'ု', 'ူ', 'ေ', 'ဲ', 'ံ', '့', 'း', '်', 'ျ', 'ြ', 'ွ', 'ှ', '၌', '၏', 'ა', 'ბ', 'გ', 'დ', 'ე', 'ვ', 'თ', 'ი', 'კ', 'ლ', 'მ', 'ნ', 'ო', 'რ', 'ს', 'ტ', 'უ', 'ფ', 'ქ', 'ღ', 'შ', 'ძ', 'წ', 'ხ', 'ჯ', 'ჹ', 'ᄅ', 'ᇐ', 'ሁ', 'ለ', 'ሉ', 'ሊ', 'ላ', 'ል', 'መ', 'ሙ', 'ሚ', 'ማ', 'ም', 'ረ', 'ሪ', 'ራ', 'ር', 'ሲ', 'ሳ', 'ስ', 'ሻ', 'ቀ', 'በ', 'ቡ', 'ቢ', 'ባ', 'ብ', 'ቦ', 'ቫ', 'ተ', 'ቱ', 'ታ', 'ት', 'ች', 'ኑ', 'ና', 'ን', 'ኖ', 'አ', 'ኤ', 'እ', 'ኩ', 'ካ', 'ክ', 'ወ', 'ዊ', 'ው', 'ዎ', 'ዓ', 'ዕ', 'ዘ', 'ዛ', 'የ', 'ዩ', 'ይ', 'ዱ', 'ዳ', 'ድ', 'ዶ', 'ጅ', 'ገ', 'ጊ', 'ጥ', 'ጫ', 'ፈ', 'ፉ', 'ፋ', 'ፎ', 'ፔ', '፡', 'Ꭰ', 'Ꭱ', 'Ꭲ', 'Ꭳ', 'Ꭴ', 'Ꭵ', 'Ꭶ', 'Ꭷ', 'Ꭸ', 'Ꭹ', 'Ꭺ', 'Ꭻ', 'Ꭼ', 'Ꭽ', 'Ꭾ', 'Ꭿ', 'Ꮀ', 'Ꮁ', 'Ꮂ', 'Ꮃ', 'Ꮄ', 'Ꮅ', 'Ꮆ', 'Ꮇ', 'Ꮈ', 'Ꮉ', 'Ꮊ', 'Ꮋ', 'Ꮌ', 'Ꮍ', 'Ꮎ', 'Ꮏ', 'Ꮐ', 'Ꮑ', 'Ꮒ', 'Ꮓ', 'Ꮔ', 'Ꮕ', 'Ꮖ', 'Ꮗ', 'Ꮘ', 'Ꮙ', 'Ꮚ', 'Ꮛ', 'Ꮜ', 'Ꮝ', 'Ꮞ', 'Ꮟ', 'Ꮠ', 'Ꮡ', 'Ꮢ', 'Ꮣ', 'Ꮤ', 'Ꮥ', 'Ꮦ', 'Ꮧ', 'Ꮨ', 'Ꮩ', 'Ꮪ', 'Ꮫ', 'Ꮬ', 'Ꮭ', 'Ꮮ', 'Ꮯ', 'Ꮰ', 'Ꮱ', 'Ꮲ', 'Ꮳ', 'Ꮴ', 'Ꮵ', 'Ꮶ', 'Ꮷ', 'Ꮸ', 'Ꮹ', 'Ꮺ', 'Ꮻ', 'Ꮼ', 'Ꮽ', 'Ꮾ', 'Ꮿ', 'Ᏸ', 'Ᏹ', 'Ᏺ', 'Ᏻ', 'Ᏼ', 'Ᏽ', 'ᏸ', 'ᏹ', 'ᏺ', 'ᏻ', 'ᏼ', 'ᏽ', 'ᐃ', 'ᐅ', 'ᐊ', 'ᐧ', 'ᐸ', 'ᑐ', 'ᑕ', 'ᑦ', 'ᒃ', 'ᒑ', 'ᒡ', 'ᓗ', 'ᔪ', 'ᕐ', 'ᕗ', 'ᕙ', 'ᖅ', 'ᖇ', 'ᗜ', 'ᗷ', 'ᙾ', 'ᚢ', 'ᚨ', 'ᚩ', 'ᚱ', 'ᚾ', 'ᛁ', 'ᛉ', 'ᛗ', 'ᛚ', 'ᛞ', 'ᛟ', 'ᜀ', 'ᜁ', 'ᜂ', 'ᜃ', 'ᜄ', 'ᜅ', 'ᜆ', 'ᜇ', 'ᜈ', 'ᜉ', 'ᜊ', 'ᜋ', 'ᜌ', 'ᜎ', 'ᜏ', 'ᜐ', 'ᜑ', 'ᜒ', 'ᜓ', '᜔', 'ក', 'ខ', 'គ', 'ង', 'ច', 'ជ', 'ដ', 'ណ', 'ន', 'ប', 'ព', 'ភ', 'ម', 'រ', 'ល', 'អ', 'ា', 'ុ', 'ួ', 'ែ', 'ោ', 'ំ', '័', '្', '᠊', '᠋', '\\u180e', 'ᠠ', 'ᠡ', 'ᠢ', 'ᠣ', 'ᠤ', 'ᠦ', 'ᠨ', 'ᠪ', 'ᠬ', 'ᠭ', 'ᠰ', 'ᠳ', 'ᠵ', 'ᠷ', 'ᡝ', 'ᡩ', 'ᡳ', 'ᡵ', 'ᢨ', 'ᩡ', 'ᰀ', 'ᰆ', 'ᰊ', 'ᰕ', 'ᰛ', 'ᰧ', 'ᰩ', 'ᰪ', 'ᰫ', 'ᰮ', 'ᰰ', 'ᰱ', 'ᰵ', 'ᰶ', '\\u1c8e', 'ᴀ', 'ᴁ', 'ᴂ', 'ᴃ', 'ᴄ', 'ᴅ', 'ᴆ', 'ᴇ', 'ᴈ', 'ᴉ', 'ᴊ', 'ᴋ', 'ᴌ', 'ᴍ', 'ᴎ', 'ᴏ', 'ᴑ', 'ᴓ', 'ᴔ', 'ᴗ', 'ᴘ', 'ᴙ', 'ᴚ', 'ᴛ', 'ᴜ', 'ᴝ', 'ᴞ', 'ᴟ', 'ᴠ', 'ᴡ', 'ᴢ', 'ᴣ', 'ᴥ', 'ᴬ', 'ᴭ', 'ᴮ', 'ᴯ', 'ᴰ', 'ᴱ', 'ᴲ', 'ᴳ', 'ᴴ', 'ᴵ', 'ᴶ', 'ᴷ', 'ᴸ', 'ᴹ', 'ᴺ', 'ᴻ', 'ᴼ', 'ᴾ', 'ᴿ', 'ᵀ', 'ᵁ', 'ᵂ', 'ᵃ', 'ᵄ', 'ᵅ', 'ᵆ', 'ᵇ', 'ᵈ', 'ᵉ', 'ᵊ', 'ᵋ', 'ᵌ', 'ᵍ', 'ᵎ', 'ᵏ', 'ᵐ', 'ᵑ', 'ᵒ', 'ᵕ', 'ᵖ', 'ᵗ', 'ᵘ', 'ᵙ', 'ᵚ', 'ᵛ', 'ᵠ', 'ᵢ', 'ᵣ', 'ᵤ', 'ᵥ', 'ᵧ', 'ᵫ', 'ᵬ', 'ᵭ', 'ᵮ', 'ᵯ', 'ᵰ', 'ᵱ', 'ᵲ', 'ᵳ', 'ᵴ', 'ᵵ', 'ᵶ', 'ᵻ', 'ᵿ', 'ᶄ', 'ᶅ', 'ᶆ', 'ᶇ', 'ᶍ', 'ᶓ', 'ᶜ', 'ᶠ', 'ᶦ', 'ᶫ', 'ᶰ', 'ᶳ', 'ᶸ', 'ᶻ', 'Ḁ', 'ḁ', 'Ḃ', 'ḃ', 'Ḅ', 'ḅ', 'Ḇ', 'ḇ', 'Ḉ', 'ḉ', 'Ḋ', 'ḋ', 'Ḍ', 'ḍ', 'Ḏ', 'ḏ', 'Ḑ', 'ḑ', 'Ḓ', 'ḓ', 'Ḕ', 'ḕ', 'Ḗ', 'ḗ', 'Ḙ', 'ḙ', 'Ḛ', 'ḛ', 'Ḝ', 'ḝ', 'Ḟ', 'ḟ', 'Ḡ', 'ḡ', 'Ḣ', 'ḣ', 'Ḥ', 'ḥ', 'Ḧ', 'ḧ', 'Ḩ', 'ḩ', 'Ḫ', 'ḫ', 'Ḭ', 'ḭ', 'Ḯ', 'ḯ', 'Ḱ', 'ḱ', 'Ḳ', 'ḳ', 'Ḵ', 'ḵ', 'Ḷ', 'ḷ', 'Ḹ', 'ḹ', 'Ḻ', 'ḻ', 'Ḽ', 'ḽ', 'Ḿ', 'ḿ', 'Ṁ', 'ṁ', 'Ṃ', 'ṃ', 'Ṅ', 'ṅ', 'Ṇ', 'ṇ', 'Ṉ', 'ṉ', 'Ṋ', 'ṋ', 'Ṍ', 'ṍ', 'Ṏ', 'ṏ', 'Ṑ', 'ṑ', 'Ṓ', 'ṓ', 'Ṕ', 'ṕ', 'Ṗ', 'ṗ', 'Ṙ', 'ṙ', 'Ṛ', 'ṛ', 'Ṝ', 'ṝ', 'Ṟ', 'ṟ', 'Ṡ', 'ṡ', 'Ṣ', 'ṣ', 'Ṥ', 'ṥ', 'Ṧ', 'ṧ', 'Ṩ', 'ṩ', 'Ṫ', 'ṫ', 'Ṭ', 'ṭ', 'Ṯ', 'ṯ', 'Ṱ', 'ṱ', 'Ṳ', 'ṳ', 'Ṵ', 'ṵ', 'Ṷ', 'ṷ', 'Ṹ', 'ṹ', 'Ṻ', 'ṻ', 'Ṽ', 'ṽ', 'Ṿ', 'ṿ', 'Ẁ', 'ẁ', 'Ẃ', 'ẃ', 'Ẅ', 'ẅ', 'Ẇ', 'ẇ', 'Ẉ', 'ẉ', 'Ẋ', 'ẋ', 'Ẍ', 'ẍ', 'Ẏ', 'ẏ', 'Ẑ', 'ẑ', 'Ẓ', 'ẓ', 'Ẕ', 'ẕ', 'ẖ', 'ẗ', 'ẘ', 'ẙ', 'ẚ', 'ẛ', 'ẞ', 'ẟ', 'Ạ', 'ạ', 'Ả', 'ả', 'Ấ', 'ấ', 'Ầ', 'ầ', 'Ẩ', 'ẩ', 'Ẫ', 'ẫ', 'Ậ', 'ậ', 'Ắ', 'ắ', 'Ằ', 'ằ', 'Ẳ', 'ẳ', 'Ẵ', 'ẵ', 'Ặ', 'ặ', 'Ẹ', 'ẹ', 'Ẻ', 'ẻ', 'Ẽ', 'ẽ', 'Ế', 'ế', 'Ề', 'ề', 'Ể', 'ể', 'Ễ', 'ễ', 'Ệ', 'ệ', 'Ỉ', 'ỉ', 'Ị', 'ị', 'Ọ', 'ọ', 'Ỏ', 'ỏ', 'Ố', 'ố', 'Ồ', 'ồ', 'Ổ', 'ổ', 'Ỗ', 'ỗ', 'Ộ', 'ộ', 'Ớ', 'ớ', 'Ờ', 'ờ', 'Ở', 'ở', 'Ỡ', 'ỡ', 'Ợ', 'ợ', 'Ụ', 'ụ', 'Ủ', 'ủ', 'Ứ', 'ứ', 'Ừ', 'ừ', 'Ử', 'ử', 'Ữ', 'ữ', 'Ự', 'ự', 'Ỳ', 'ỳ', 'Ỵ', 'ỵ', 'Ỷ', 'ỷ', 'Ỹ', 'ỹ', 'ἀ', 'ἁ', 'ἂ', 'ἃ', 'ἄ', 'ἅ', 'ἆ', 'Ἀ', 'Ἁ', 'Ἄ', 'ἐ', 'ἑ', 'ἔ', 'ἕ', 'Ἐ', 'Ἑ', 'Ἔ', 'ἠ', 'ἡ', 'ἢ', 'ἣ', 'ἤ', 'ἥ', 'ἦ', 'Ἠ', 'Ἡ', 'Ἢ', 'Ἥ', 'ἰ', 'ἱ', 'ἴ', 'ἵ', 'ἶ', 'Ἰ', 'Ἴ', 'ὀ', 'ὁ', 'ὃ', 'ὄ', 'ὅ', 'Ὀ', 'Ὁ', 'Ὅ', 'ὐ', 'ὑ', 'ὔ', 'ὕ', 'ὖ', 'ὗ', 'Ὑ', 'ὠ', 'ὡ', 'ὢ', 'ὤ', 'ὥ', 'ὦ', 'Ὠ', 'ὰ', 'ά', 'ὲ', 'έ', 'ὴ', 'ή', 'ὶ', 'ί', 'ὸ', 'ό', 'ὺ', 'ύ', 'ὼ', 'ώ', 'ᾖ', 'ᾰ', 'ᾱ', 'ᾳ', 'ᾶ', 'ᾷ', '᾽', '᾿', 'ῃ', 'ῆ', 'ῇ', 'ῑ', 'ῖ', 'ῤ', 'ῥ', 'ῦ', 'Ῥ', 'ῳ', 'ῴ', 'ῶ', 'ῷ', '\\u200b', '\\u200c', '\\u200d', '\\u200e', '\\u200f', '‐', '‑', '‒', '–', '—', '―', '‖', '‘', '’', '‚', '“', '”', '„', '‟', '†', '‡', '•', '‣', '․', '‥', '…', '‧', '\\u202a', '\\u202b', '\\u202c', '\\u202d', '\\u202e', '‰', '′', '″', '‸', '‹', '›', '※', '‼', '‽', '‾', '‿', '⁂', '⁃', '⁄', '⁈', '⁉', '⁓', '\\u2060', '\\u2061', '\\u2066', '\\u2069', '⁰', '⁴', '⁵', '⁶', '⁷', '⁸', '⁹', '⁻', '⁽', '⁾', 'ⁿ', '₀', '₁', '₂', '₃', '₍', 'ₒ', '₢', '₤', '₦', '₩', '₪', '₫', '€', '₭', '₮', '₱', '₴', '₹', '₺', '₽', '₾', '⃣', '℃', '℅', '℉', 'ℏ', 'ℒ', 'ℓ', 'ℕ', '№', '℗', 'ℙ', 'ℚ', 'ℛ', 'ℝ', '℞', '℠', '™', 'ℤ', 'Ω', '℩', 'K', 'Å', 'ℬ', 'ℯ', 'ℰ', 'Ⅎ', 'ℳ', 'ℴ', 'ℵ', 'ℹ', '⅄', 'ⅎ', '⅓', '⅔', '⅕', '⅖', '⅗', '⅘', '⅙', '⅛', '⅜', '⅝', '⅞', 'Ⅰ', 'Ⅱ', 'Ⅲ', 'Ⅳ', 'Ⅴ', 'Ⅵ', 'Ⅶ', 'Ⅷ', 'Ⅸ', 'Ⅹ', 'Ⅺ', 'Ⅻ', 'Ⅼ', 'Ⅽ', 'Ⅾ', 'Ⅿ', 'ⅰ', 'ⅱ', 'ⅲ', 'ⅳ', 'ⅴ', 'ⅵ', 'ⅶ', 'ⅷ', 'ⅸ', 'ⅹ', 'ⅺ', 'ⅻ', 'ⅼ', 'ⅽ', 'ⅾ', 'ⅿ', '←', '↑', '→', '↓', '↔', '↕', '↖', '↗', '↘', '↙', '↝', '↣', '↦', '↩', '↪', '↬', '↳', '↵', '↷', '↹', '↺', '↻', '↼', '↽', '⇀', '⇈', '⇋', '⇌', '⇏', '⇐', '⇑', '⇒', '⇓', '⇔', '⇠', '⇢', '⇣', '⇧', '⇪', '∀', '∂', '∃', '∅', '∆', '∇', '∈', '∉', '∋', '∎', '∏', '∑', '−', '∓', '∕', '∗', '∘', '∙', '√', '∝', '∞', '∠', '∣', '∥', '∧', '∨', '∩', '∪', '∫', '∬', '∮', '∴', '∶', '∷', '∸', '∼', '∽', '≀', '≃', '≅', '≈', '≒', '≝', '≟', '≠', '≡', '≤', '≥', '≪', '≫', '≯', '≱', '≲', '≳', '≻', '⊁', '⊂', '⊃', '⊆', '⊍', '⊕', '⊗', '⊙', '⊞', '⊟', '⊠', '⊢', '⊤', '⊥', '⊦', '⊸', '⊹', '⊻', '⊼', '⊽', '⋂', '⋄', '⋅', '⋆', '⋘', '⋙', '⋮', '⋯', '⋱', '⌀', '⌃', '⌄', '⌇', '⌈', '⌉', '⌊', '⌋', '⌐', '⌒', '⌗', '⌘', '⌚', '⌛', '⌠', '⌥', '⌦', '〈', '〉', '⌫', '⎖', '⎧', '⎫', '⎯', '⏎', '⏚', '⏟', '⏮', '⏯', '⏰', '⏱', '⏺', '①', '②', '③', '④', '⑤', '⑥', '⑦', '⑧', '⑨', 'Ⓐ', 'Ⓒ', 'Ⓓ', 'Ⓔ', 'Ⓖ', 'Ⓚ', 'Ⓛ', 'Ⓜ', 'Ⓞ', 'Ⓟ', 'Ⓡ', 'Ⓢ', 'Ⓣ', 'Ⓥ', 'ⓐ', 'ⓑ', 'ⓒ', 'ⓓ', 'ⓔ', 'ⓕ', 'ⓖ', 'ⓘ', 'ⓛ', 'ⓝ', 'ⓞ', 'ⓟ', 'ⓡ', 'ⓢ', 'ⓤ', 'ⓥ', 'ⓧ', 'ⓨ', '─', '━', '│', '┃', '┌', '┐', '┓', '└', '┗', '┘', '┚', '┛', '├', '┤', '┬', '┴', '┻', '┼', '═', '║', '╔', '╕', '╗', '╚', '╝', '╠', '╢', '╣', '╦', '╩', '╪', '╬', '╭', '╮', '╯', '╰', '╱', '╲', '╳', '╹', '▀', '▁', '▂', '▃', '▄', '▅', '▆', '▇', '█', '▌', '▍', '▐', '░', '▒', '▓', '▗', '■', '□', '▢', '▣', '▥', '▧', '▩', '▪', '▬', '▭', '▱', '▲', '△', '▴', '▶', '▷', '▸', '►', '▼', '▽', '▾', '◀', '◁', '◄', '◆', '◇', '◈', '◉', '◊', '○', '◌', '◎', '●', '◐', '◕', '◙', '◝', '◟', '◡', '◢', '◣', '◤', '◥', '◦', '◻', '◼', '◾', '☀', '☁', '☂', '☃', '☄', '★', '☆', '☇', '☈', '☉', '☊', '☋', '☌', '☍', '☎', '☏', '☐', '☑', '☒', '☓', '☔', '☕', '☖', '☗', '☘', '☙', '☚', '☛', '☜', '☝', '☞', '☟', '☠', '☡', '☢', '☣', '☤', '☥', '☦', '☧', '☨', '☩', '☪', '☫', '☬', '☭', '☮', '☯', '☰', '☱', '☲', '☳', '☴', '☵', '☶', '☷', '☸', '☹', '☺', '☻', '☼', '☽', '☾', '☿', '♀', '♁', '♂', '♃', '♄', '♅', '♆', '♇', '♈', '♉', '♊', '♋', '♌', '♍', '♎', '♏', '♐', '♑', '♒', '♓', '♔', '♕', '♖', '♗', '♘', '♙', '♚', '♛', '♜', '♝', '♞', '♟', '♠', '♡', '♢', '♣', '♤', '♥', '♦', '♧', '♨', '♩', '♪', '♫', '♬', '♭', '♮', '♯', '♰', '♱', '♲', '♳', '♴', '♵', '♶', '♷', '♸', '♹', '♺', '♻', '♼', '♽', '♾', '♿', '⚀', '⚁', '⚂', '⚃', '⚄', '⚅', '⚆', '⚇', '⚈', '⚉', '⚊', '⚋', '⚌', '⚍', '⚎', '⚏', '⚐', '⚑', '⚒', '⚓', '⚔', '⚕', '⚖', '⚗', '⚘', '⚙', '⚚', '⚛', '⚜', '⚝', '⚞', '⚟', '⚠', '⚡', '⚢', '⚣', '⚤', '⚥', '⚦', '⚧', '⚨', '⚩', '⚪', '⚫', '⚬', '⚭', '⚮', '⚯', '⚰', '⚱', '⚲', '⚳', '⚴', '⚵', '⚶', '⚷', '⚸', '⚹', '⚺', '⚻', '⚼', '⚽', '⚾', '⚿', '⛀', '⛁', '⛂', '⛃', '⛄', '⛅', '⛆', '⛇', '⛈', '⛉', '⛊', '⛋', '⛌', '⛍', '⛎', '⛏', '⛐', '⛑', '⛒', '⛓', '⛔', '⛕', '⛖', '⛗', '⛘', '⛙', '⛚', '⛛', '⛜', '⛝', '⛞', '⛟', '⛠', '⛡', '⛢', '⛣', '⛤', '⛥', '⛦', '⛧', '⛨', '⛩', '⛪', '⛫', '⛬', '⛭', '⛮', '⛯', '⛰', '⛱', '⛲', '⛳', '⛴', '⛵', '⛶', '⛷', '⛸', '⛹', '⛺', '⛻', '⛼', '⛽', '⛾', '⛿', '✂', '✅', '✈', '✉', '✊', '✋', '✌', '✍', '✎', '✏', '✐', '✓', '✔', '✕', '✖', '✗', '✘', '✙', '✚', '✝', '✞', '✟', '✠', '✦', '✧', '✨', '✪', '✭', '✮', '✯', '✰', '✴', '✶', '✸', '✹', '✻', '✿', '❄', '❅', '❋', '❌', '❍', '❏', '❑', '❓', '❖', '❗', '❝', '❞', '❣', '❤', '❥', '❦', '❧', '❮', '❯', '❶', '❷', '❸', '❹', '❺', '❻', '➊', '➋', '➌', '➍', '➎', '➏', '➐', '➑', '➙', '➜', '➝', '➡', '➤', '➻', '➼', '➽', '➿', '⟨', '⟩', '⟵', '⟶', '⟹', '⟺', '⟼', '⠀', '⠁', '⠂', '⠃', '⠄', '⠅', '⠆', '⠇', '⠉', '⠊', '⠋', '⠌', '⠍', '⠎', '⠏', '⠐', '⠑', '⠓', '⠕', '⠖', '⠗', '⠙', '⠚', '⠛', '⠝', '⠞', '⠟', '⠠', '⠡', '⠢', '⠣', '⠥', '⠦', '⠧', '⠨', '⠩', '⠪', '⠫', '⠬', '⠭', '⠮', '⠯', '⠰', '⠱', '⠲', '⠳', '⠵', '⠶', '⠹', '⠺', '⠼', '⠽', '⠾', '⠿', '⤻', '⦁', '⧉', '⧐', '⧭', '⧻', '⨠', '⨪', '⩽', '⬅', '⬆', '⬇', '⬚', '⬛', '⭐', 'Ⱡ', 'Ᵽ', 'Ⱪ', '⸘', '⸢', '⸣', '⸶', '⸷', '⸸', '⹋', '⺌', '⺍', '⻧', '⽂', '⽟', '⽣', '⽴', '⽼', '⾬', '⾺', '\\u2fff', '、', '。', '〃', '々', '〆', '〇', '〈', '〉', '《', '》', '「', '」', '『', '』', '【', '】', '〒', '〓', '〔', '〕', '〖', '〗', '〜', '〰', '〽', 'ぁ', 'あ', 'ぃ', 'い', 'ぅ', 'う', 'ぇ', 'え', 'ぉ', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'ぢ', 'っ', 'つ', 'づ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ぬ', 'ね', 'の', 'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゅ', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'わ', 'ゐ', 'ゑ', 'を', 'ん', '゚', '゛', '゜', 'ゝ', 'ゞ', '゠', 'ァ', 'ア', 'ィ', 'イ', 'ゥ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', 'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', 'タ', 'ダ', 'チ', 'ヂ', 'ッ', 'ツ', 'ヅ', 'テ', 'デ', 'ト', 'ド', 'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', 'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', 'マ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ヮ', 'ワ', 'ヰ', 'ヱ', 'ヲ', 'ン', 'ヴ', 'ヵ', 'ヶ', 'ヷ', 'ヸ', 'ヹ', 'ヺ', '・', 'ー', 'ヽ', 'ヾ', 'ヿ', 'ㄅ', 'ㄆ', 'ㄇ', 'ㄈ', 'ㄉ', 'ㄊ', 'ㄋ', 'ㄌ', 'ㄍ', 'ㄎ', 'ㄏ', 'ㄐ', 'ㄑ', 'ㄒ', 'ㄓ', 'ㄔ', 'ㄕ', 'ㄖ', 'ㄗ', 'ㄘ', 'ㄙ', 'ㄚ', 'ㄛ', 'ㄜ', 'ㄝ', 'ㄞ', 'ㄟ', 'ㄠ', 'ㄡ', 'ㄢ', 'ㄣ', 'ㄤ', 'ㄥ', 'ㄦ', 'ㄧ', 'ㄨ', 'ㄩ', 'ㄪ', 'ㄫ', 'ㄬ', 'ㄭ', 'ㄮ', 'ㄯ', 'ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ', 'ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ', 'ㅤ', 'ㆁ', 'ㆍ', 'ㆠ', 'ㆡ', 'ㆢ', 'ㆣ', 'ㆤ', 'ㆥ', 'ㆦ', 'ㆧ', 'ㆨ', 'ㆩ', 'ㆪ', 'ㆫ', 'ㆬ', 'ㆭ', 'ㆮ', 'ㆯ', 'ㆰ', 'ㆱ', 'ㆲ', 'ㆳ', 'ㆴ', 'ㆵ', 'ㆶ', 'ㆷ', 'ㆸ', 'ㆹ', 'ㆺ', 'ㇰ', 'ㇱ', 'ㇲ', 'ㇳ', 'ㇴ', 'ㇵ', 'ㇶ', 'ㇷ', 'ㇸ', 'ㇹ', 'ㇺ', 'ㇻ', 'ㇼ', 'ㇽ', 'ㇾ', 'ㇿ', '㉨', '㎈', '㎛', '㎝', '㎲', '㏌', '㐅', '㐱', '㑒', '㗋', '㗎', '㬹', '㱵', '㳺', '㼭', '䕫', '䕶', '䞇', '䠀', '一', '丁', '丂', '七', '丅', '万', '丈', '三', '上', '下', '不', '与', '丑', '专', '且', '世', '丘', '业', '东', '丝', '丞', '丟', '両', '丢', '两', '严', '並', '丨', '丩', '个', '丫', '中', '丰', '串', '临', '丶', '丸', '丹', '为', '主', '丼', '丽', '举', '丿', '乁', '乃', '久', '么', '义', '之', '乌', '乍', '乎', '乐', '乕', '乗', '乘', '乙', '乚', '乜', '九', '乞', '也', '习', '乡', '书', '买', '乱', '乳', '乾', '亀', '亂', '亅', '了', '予', '争', '事', '二', '于', '云', '互', '五', '井', '亘', '亚', '些', '亜', '亞', '亡', '交', '亥', '亦', '产', '亨', '享', '京', '亭', '亮', '亲', '人', '亻', '亿', '什', '仁', '仄', '仆', '今', '介', '仍', '从', '仔', '仕', '他', '仗', '付', '仙', '仚', '仟', '代', '令', '以', '仪', '们', '仮', '仰', '仲', '件', '价', '任', '份', '仿', '企', '伊', '伍', '伏', '伐', '休', '众', '优', '会', '伝', '伟', '传', '伤', '伦', '伯', '估', '伴', '伶', '伸', '伺', '似', '伽', '但', '佇', '佈', '位', '低', '住', '佐', '佑', '体', '何', '佘', '余', '佛', '作', '佟', '你', '佢', '佣', '佩', '佪', '佰', '佳', '併', '使', '來', '例', '侍', '侏', '侘', '供', '依', '侠', '価', '侧', '侨', '侬', '侮', '侯', '侵', '侶', '便', '係', '促', '俄', '俊', '俗', '俘', '保', '俞', '俟', '俠', '信', '修', '俱', '俵', '俺', '俾', '倅', '倉', '個', '倍', '們', '倒', '倔', '倘', '候', '借', '倡', '値', '倨', '倩', '倪', '倫', '倶', '倹', '值', '偃', '假', '偉', '偏', '偕', '做', '停', '健', '側', '偵', '偶', '偷', '偽', '偿', '傅', '傍', '傑', '傘', '備', '储', '催', '傳', '傷', '傻', '傾', '僅', '僉', '僊', '働', '像', '僑', '僕', '僚', '僧', '價', '儀', '儁', '儂', '億', '儉', '儒', '儘', '儚', '償', '優', '儲', '儿', '兀', '元', '兄', '充', '兆', '兇', '先', '光', '兊', '克', '兌', '免', '兎', '児', '兒', '兔', '党', '兠', '入', '內', '全', '兩', '兪', '八', '公', '六', '兮', '兰', '共', '关', '兴', '兵', '其', '具', '典', '养', '兼', '兽', '冀', '冂', '内', '円', '冇', '冉', '冊', '再', '冒', '冖', '冗', '写', '军', '冠', '冦', '冧', '冬', '冯', '冰', '冲', '决', '况', '冷', '冻', '净', '凄', '准', '凉', '凌', '凍', '减', '凖', '凛', '凝', '几', '凡', '凤', '処', '凭', '凯', '凰', '凱', '凳', '凵', '凶', '凸', '凹', '出', '击', '函', '刀', '刂', '刃', '分', '切', '刈', '刊', '刋', '刑', '划', '列', '刘', '则', '刚', '创', '初', '判', '別', '刧', '刨', '利', '刪', '别', '到', '制', '刷', '券', '刺', '刻', '剃', '則', '剉', '削', '剌', '前', '剑', '剛', '剣', '剤', '剥', '剩', '剪', '副', '割', '創', '劃', '劇', '劈', '劉', '劍', '劒', '劔', '力', '办', '功', '加', '务', '劣', '动', '助', '努', '励', '劳', '労', '効', '势', '勁', '勃', '勅', '勇', '勉', '勒', '動', '勘', '務', '勝', '勞', '勢', '勤', '勧', '勵', '勹', '勺', '勾', '勿', '匂', '包', '匍', '匐', '匕', '化', '北', '匚', '匠', '匡', '匣', '匪', '匯', '匹', '区', '医', '匿', '區', '十', '千', '升', '午', '半', '卍', '华', '协', '卐', '卑', '卒', '卓', '協', '单', '卖', '南', '単', '博', '卞', '占', '卡', '卢', '卦', '卧', '卩', '卫', '卯', '印', '危', '即', '却', '卵', '卷', '卸', '卻', '卽', '卿', '厂', '厅', '历', '厕', '厚', '原', '厠', '厥', '厦', '厨', '厲', '厳', '厶', '去', '县', '参', '參', '又', '叉', '及', '友', '双', '反', '収', '发', '叔', '取', '受', '变', '叚', '叛', '叡', '叢', '口', '古', '句', '另', '叩', '只', '叫', '召', '叭', '可', '台', '叱', '史', '右', '叶', '号', '司', '叹', '吃', '各', '合', '吉', '吊', '同', '名', '后', '吏', '吐', '向', '吓', '吕', '吗', '君', '否', '吧', '含', '听', '启', '吳', '吴', '吶', '吸', '吹', '吻', '吼', '吾', '呀', '呂', '呃', '呆', '呈', '告', '呗', '员', '呢', '周', '呪', '味', '呵', '呼', '命', '咀', '咁', '咋', '和', '咒', '咖', '咗', '咝', '咤', '咨', '咩', '咪', '咫', '咯', '咲', '咳', '咸', '咽', '咿', '哀', '品', '哄', '哈', '哉', '哋', '响', '員', '哥', '哦', '哩', '哪', '哭', '哲', '唄', '唆', '唇', '唐', '唔', '唤', '售', '唯', '唱', '商', '啊', '問', '啓', '啞', '啟', '啡', '啤', '啥', '啦', '啱', '啲', '啼', '喂', '善', '喇', '喉', '喊', '喋', '喚', '喜', '喝', '喧', '喪', '喫', '喬', '單', '喰', '喱', '喵', '営', '喺', '喿', '嗅', '嗎', '嗚', '嗟', '嗡', '嗣', '嗰', '嘅', '嘉', '嘎', '嘏', '嘗', '嘘', '嘛', '嘢', '嘩', '嘴', '嘿', '噂', '噌', '噎', '器', '噬', '噱', '噴', '嚇', '嚢', '嚨', '嚮', '嚴', '嚼', '囂', '囍', '囗', '囘', '囚', '四', '回', '因', '团', '団', '囪', '园', '困', '囲', '図', '围', '固', '国', '图', '圆', '圈', '國', '圍', '圏', '園', '圓', '圖', '團', '圞', '土', '圣', '圧', '在', '圭', '地', '圳', '场', '圾', '址', '坂', '均', '坊', '坎', '坏', '坐', '坑', '块', '坚', '坛', '坞', '坤', '坦', '坪', '垂', '垃', '型', '垛', '垜', '垢', '垣', '垩', '垮', '埃', '埋', '城', '域', '埠', '執', '培', '基', '埼', '堀', '堂', '堃', '堅', '堆', '堇', '堞', '堡', '堤', '堪', '報', '場', '塊', '塌', '塔', '塗', '塘', '塚', '塞', '塟', '塩', '塵', '塾', '境', '墉', '墊', '墓', '増', '墙', '增', '墨', '墮', '墳', '壁', '壇', '壊', '壓', '壘', '壞', '壤', '士', '壮', '声', '売', '壶', '壷', '壺', '壽', '处', '备', '変', '复', '夏', '夕', '外', '多', '夜', '够', '夠', '夢', '夥', '大', '天', '太', '夫', '央', '失', '头', '夷', '夸', '夹', '夺', '夾', '奇', '奈', '奉', '奋', '奏', '契', '奔', '奖', '套', '奥', '奧', '奨', '奪', '奮', '女', '奴', '奶', '她', '好', '如', '妃', '妄', '妆', '妇', '妈', '妊', '妍', '妒', '妖', '妙', '妝', '妞', '妤', '妨', '妮', '妹', '妻', '姆', '姉', '始', '姐', '姑', '姓', '委', '姗', '姚', '姜', '姥', '姨', '姫', '姬', '姻', '姿', '威', '娃', '娇', '娘', '娜', '娟', '娠', '娥', '娱', '娶', '婁', '婆', '婚', '婢', '婦', '婧', '婪', '婿', '媒', '媪', '媽', '嫁', '嫉', '嫌', '嫗', '嫩', '嫪', '嬉', '嬢', '嬾', '子', '孔', '字', '存', '孙', '孚', '孛', '孝', '孟', '季', '孤', '学', '孩', '孫', '孰', '學', '宁', '宂', '它', '宅', '宇', '守', '安', '宋', '完', '宏', '宗', '官', '宙', '定', '宛', '宜', '宝', '实', '実', '客', '宣', '室', '宦', '宫', '宮', '宰', '害', '宴', '宵', '家', '容', '宾', '宿', '寂', '寄', '寅', '密', '寇', '富', '寒', '寔', '寝', '寞', '察', '寥', '實', '寧', '寨', '審', '寫', '寬', '寰', '寳', '寶', '寸', '对', '寺', '寻', '导', '対', '寿', '封', '専', '射', '将', '將', '專', '尉', '尊', '尋', '對', '導', '小', '少', '尔', '尖', '尘', '尚', '尝', '尠', '尢', '尤', '尧', '就', '尸', '尹', '尺', '尻', '尼', '尽', '尾', '尿', '局', '屁', '层', '居', '屈', '届', '屋', '屍', '屎', '屏', '屑', '展', '属', '屠', '屢', '層', '履', '山', '屿', '岁', '岐', '岑', '岗', '岛', '岡', '岩', '岱', '岳', '岸', '峌', '峡', '峥', '峦', '峨', '峪', '峯', '峰', '島', '峻', '崇', '崎', '崑', '崔', '崖', '崧', '崩', '嵐', '嵩', '嵯', '嶧', '嶮', '嶴', '嶺', '嶼', '嶽', '巖', '巛', '巜', '川', '州', '巡', '巢', '巣', '工', '左', '巧', '巨', '巫', '差', '己', '已', '巴', '巵', '巷', '巻', '巽', '巾', '帀', '币', '市', '布', '帅', '帆', '师', '希', '帕', '帖', '帛', '帝', '帥', '带', '師', '席', '帮', '帯', '帰', '帳', '帶', '常', '帽', '幅', '幌', '幕', '幟', '幢', '幣', '幫', '干', '平', '年', '并', '幸', '幹', '幺', '幻', '幼', '幽', '幾', '广', '庁', '広', '庄', '庆', '床', '序', '应', '底', '店', '庙', '庚', '府', '废', '度', '座', '庫', '庭', '庵', '庶', '康', '庸', '庻', '庾', '廁', '廃', '廉', '廊', '廓', '廖', '廚', '廟', '廢', '廣', '廩', '廬', '廳', '延', '廷', '建', '廻', '廾', '开', '弁', '异', '弃', '弄', '弈', '弊', '式', '弓', '引', '弗', '弘', '弛', '弟', '张', '弥', '弦', '弧', '弱', '張', '強', '弹', '强', '弼', '弾', '彀', '彈', '彎', '归', '当', '录', '彙', '彚', '彡', '形', '彥', '彦', '彩', '彪', '彫', '彬', '彭', '影', '彳', '役', '彼', '往', '征', '径', '待', '很', '徉', '律', '後', '徐', '徑', '徒', '従', '得', '徙', '從', '御', '復', '循', '微', '徳', '徴', '徵', '德', '徹', '徽', '心', '忄', '必', '忆', '忌', '忍', '忎', '志', '忘', '忙', '応', '忠', '快', '忱', '念', '忼', '忽', '忿', '怀', '态', '怎', '怒', '怕', '怖', '思', '怠', '怡', '急', '性', '怨', '怪', '总', '恆', '恋', '恍', '恐', '恒', '恢', '恣', '恥', '恨', '恩', '恪', '恭', '息', '恰', '恵', '恶', '悉', '悔', '悖', '悟', '悠', '患', '悦', '您', '悩', '悪', '悬', '悲', '悴', '悶', '悼', '情', '惑', '惚', '惜', '惟', '惠', '惡', '惧', '惨', '惰', '想', '惹', '惺', '愈', '意', '愚', '愛', '感', '愧', '愷', '愽', '愿', '慇', '慈', '態', '慎', '慕', '慘', '慣', '慧', '慨', '慮', '慵', '慶', '慾', '憊', '憐', '憑', '憔', '憚', '憤', '憧', '憩', '憲', '憶', '懂', '懃', '懈', '應', '懌', '懐', '懲', '懷', '懸', '懼', '懿', '戀', '戈', '戊', '戌', '戎', '戏', '成', '我', '戒', '戕', '或', '战', '戚', '戟', '戦', '戰', '戲', '戳', '戴', '戶', '户', '戸', '戻', '房', '所', '扁', '扇', '手', '扌', '才', '扎', '扐', '打', '払', '托', '扛', '扣', '执', '扫', '扬', '扭', '扯', '扰', '扱', '扳', '扶', '批', '找', '承', '技', '抉', '把', '抑', '抓', '投', '抖', '抗', '折', '抛', '抜', '抝', '択', '护', '报', '披', '抬', '抱', '抵', '抹', '押', '抽', '拂', '拄', '担', '拆', '拇', '拉', '拍', '拒', '拔', '拖', '拗', '拘', '招', '拜', '拝', '拠', '拡', '拥', '拨', '择', '括', '拳', '拶', '拷', '拼', '拾', '拿', '持', '挂', '指', '按', '挑', '挖', '挙', '挟', '挨', '挪', '振', '挸', '挺', '挽', '捂', '捅', '捉', '捌', '捏', '捐', '捕', '损', '捧', '捨', '据', '捲', '捶', '捷', '捻', '掂', '掃', '授', '掉', '掌', '排', '掘', '掛', '掠', '採', '探', '掣', '接', '控', '推', '掩', '掲', '掴', '揃', '揆', '揈', '揉', '描', '提', '插', '揚', '換', '握', '揭', '揮', '援', '揷', '揺', '損', '搏', '搓', '搖', '搞', '搥', '搪', '搬', '搭', '搵', '携', '搾', '摁', '摂', '摄', '摇', '摔', '摘', '摟', '摩', '摭', '摸', '撃', '撇', '撒', '撕', '撞', '撤', '撥', '撫', '播', '撲', '撳', '撻', '撾', '擁', '擄', '擅', '擊', '操', '擒', '擔', '據', '擠', '擡', '擢', '擬', '擲', '擺', '擾', '攀', '攔', '攙', '攝', '攞', '攫', '支', '攴', '攵', '收', '攷', '改', '攻', '放', '政', '故', '效', '敌', '敍', '敎', '敏', '救', '敗', '敘', '教', '敝', '敢', '散', '敦', '敬', '数', '敲', '整', '敵', '敷', '數', '文', '斉', '斋', '斌', '斑', '斗', '料', '斛', '斜', '斟', '斤', '斥', '斧', '斩', '斫', '斬', '断', '斯', '新', '斷', '方', '於', '施', '旁', '旂', '旃', '旅', '旋', '旌', '族', '旗', '无', '既', '旣', '日', '旦', '旧', '旨', '早', '旬', '旭', '旱', '时', '旷', '旺', '昂', '昆', '昇', '昉', '昌', '明', '昏', '易', '昔', '星', '映', '春', '昧', '昨', '昭', '是', '昱', '昶', '昼', '時', '晃', '晉', '晋', '晏', '晒', '晓', '晖', '晚', '晝', '晟', '晦', '晨', '晩', '普', '景', '晴', '晶', '智', '暁', '暈', '暉', '暑', '暖', '暗', '暦', '暨', '暫', '暮', '暴', '曁', '曆', '曇', '曉', '曖', '曜', '曰', '曲', '更', '書', '曹', '曼', '曾', '替', '最', '會', '月', '有', '朋', '服', '朗', '望', '朝', '期', '朦', '朧', '木', '未', '末', '本', '札', '术', '朱', '朵', '机', '杀', '权', '杉', '李', '材', '村', '杖', '杜', '束', '条', '来', '杨', '杭', '杯', '杰', '東', '杲', '杳', '杵', '杷', '松', '板', '极', '构', '枇', '枌', '析', '枓', '林', '枚', '果', '枝', '枠', '枣', '枪', '枫', '枯', '枱', '架', '柄', '柏', '某', '柑', '柒', '染', '柔', '柚', '柜', '查', '柯', '柱', '柳', '柴', '柵', '査', '柿', '栃', '栄', '标', '树', '栖', '栗', '校', '株', '样', '核', '根', '格', '栽', '桀', '桂', '桃', '案', '桌', '桐', '桑', '桔', '桜', '桢', '桥', '桦', '桿', '梁', '梅', '梗', '條', '梢', '梦', '梧', '梨', '梭', '梯', '械', '梱', '梳', '梶', '棄', '棋', '棒', '棕', '棚', '棟', '棠', '棧', '森', '棲', '棹', '椅', '植', '椎', '椒', '検', '椿', '楊', '楓', '楔', '楚', '楢', '楨', '業', '極', '楷', '楼', '楽', '榀', '概', '榆', '榊', '榛', '榜', '榮', '榴', '槁', '槇', '構', '槌', '槍', '槎', '様', '槩', '槪', '槱', '槻', '槽', '樂', '樊', '樓', '標', '樟', '模', '樣', '権', '横', '樵', '樹', '樽', '樾', '橋', '橘', '橙', '橛', '機', '橫', '檀', '檄', '檔', '檟', '櫃', '欄', '權', '欒', '欠', '次', '欢', '欣', '欧', '欲', '欹', '欺', '欽', '款', '歇', '歌', '歐', '歓', '歛', '歟', '歡', '止', '正', '此', '步', '武', '歩', '歪', '歯', '歲', '歳', '歴', '歷', '歸', '死', '殊', '残', '殕', '殖', '殤', '殭', '殲', '殴', '段', '殷', '殺', '殻', '殿', '毀', '毁', '毅', '毆', '毋', '毌', '母', '毎', '每', '毐', '毒', '毓', '比', '毕', '毘', '毛', '氏', '民', '气', '気', '氣', '氧', '水', '氵', '氷', '永', '汁', '求', '汇', '汉', '汎', '汗', '汚', '汝', '江', '池', '污', '汤', '汪', '汰', '汴', '汶', '決', '汽', '汾', '沈', '沉', '沌', '沒', '沖', '沙', '沛', '沟', '没', '沢', '河', '沸', '油', '治', '沼', '沾', '沿', '況', '泄', '泉', '泊', '法', '泗', '泛', '泞', '泡', '波', '泣', '泥', '注', '泪', '泮', '泰', '泳', '泸', '泼', '泽', '洁', '洋', '洌', '洗', '洛', '洞', '津', '洪', '洮', '洲', '活', '派', '流', '浄', '浅', '测', '济', '浏', '浙', '浚', '浜', '浣', '浦', '浩', '浪', '浮', '浴', '海', '浸', '涂', '消', '涕', '涙', '涛', '涨', '涯', '液', '涵', '涼', '淆', '淋', '淑', '淞', '淡', '淤', '淦', '淨', '淪', '淫', '淮', '深', '淵', '混', '淸', '淺', '添', '淼', '清', '済', '渉', '渋', '渔', '渕', '減', '渝', '渟', '渠', '渡', '温', '測', '港', '游', '渾', '湖', '湘', '湛', '湧', '湯', '湳', '湾', '満', '溈', '溏', '源', '準', '溜', '溝', '溢', '溪', '溫', '溯', '溶', '溺', '滄', '滅', '滇', '滉', '滋', '滑', '滔', '滕', '滚', '滝', '滞', '满', '滨', '滲', '滴', '滷', '滿', '漁', '漂', '漆', '漏', '漓', '演', '漕', '漠', '漢', '漫', '漬', '漸', '漿', '潍', '潘', '潛', '潜', '潟', '潤', '潭', '潮', '潰', '澂', '澄', '澎', '澤', '澮', '澳', '澹', '激', '濁', '濃', '濕', '濟', '濠', '濤', '濦', '濬', '濮', '濯', '濱', '瀋', '瀏', '瀬', '瀾', '灣', '火', '灬', '灭', '灯', '灰', '灵', '灶', '灸', '灼', '災', '灾', '灿', '炅', '炆', '炉', '炎', '炒', '炙', '炫', '炭', '炮', '炯', '炳', '炸', '点', '為', '烂', '烈', '烏', '烛', '烟', '烤', '烦', '烧', '热', '焉', '焗', '焚', '無', '焦', '然', '焼', '煌', '煎', '煓', '煙', '煞', '煦', '照', '煨', '煩', '煮', '煳', '煸', '煽', '熊', '熙', '熟', '熱', '熹', '熾', '燃', '燄', '燈', '燉', '燊', '燎', '燒', '燕', '燙', '營', '燥', '燭', '燮', '爆', '爇', '爛', '爪', '爭', '爰', '爱', '爲', '爵', '父', '爷', '爸', '爹', '爺', '爻', '爽', '爾', '片', '版', '牌', '牍', '牒', '牙', '牛', '牟', '牠', '牡', '牢', '牧', '物', '牯', '牲', '特', '牺', '牽', '犀', '犁', '犍', '犠', '犬', '犯', '状', '狀', '狂', '狐', '狗', '狙', '狠', '狢', '独', '狭', '狮', '狸', '狹', '狼', '狽', '猙', '猛', '猪', '猫', '献', '猴', '猶', '猿', '獄', '獅', '獏', '獣', '獨', '獰', '獲', '獵', '獸', '獻', '玄', '率', '玉', '王', '玛', '玩', '环', '现', '玲', '玻', '珀', '珈', '珊', '珍', '珠', '班', '現', '球', '理', '琉', '琥', '琦', '琲', '琳', '琴', '琼', '瑄', '瑚', '瑛', '瑜', '瑞', '瑠', '瑩', '瑪', '瑭', '璃', '璈', '璉', '璐', '璠', '璧', '環', '瓊', '瓜', '瓢', '瓣', '瓦', '瓶', '甄', '甎', '甔', '甘', '甚', '甜', '生', '產', '産', '甦', '用', '甫', '甬', '甯', '田', '由', '甲', '申', '电', '男', '甸', '町', '画', '畀', '界', '畎', '畏', '畑', '留', '畝', '畢', '略', '畧', '番', '畫', '異', '畳', '當', '畿', '疆', '疊', '疑', '疫', '疲', '疼', '疾', '病', '症', '痛', '痩', '痰', '痴', '痿', '瘋', '瘤', '瘾', '療', '癌', '癎', '癖', '癲', '癸', '発', '登', '發', '白', '百', '的', '皆', '皇', '皎', '皓', '皖', '皞', '皮', '皿', '盃', '盆', '盈', '益', '盍', '盐', '监', '盖', '盗', '盘', '盛', '盟', '盡', '監', '盤', '盧', '目', '盲', '直', '相', '盻', '盼', '盾', '省', '眈', '眉', '看', '県', '眞', '真', '眠', '眩', '眷', '眺', '眼', '眾', '着', '睂', '睇', '睛', '督', '睦', '睨', '睹', '睿', '瞑', '瞞', '瞩', '瞬', '瞿', '矅', '矛', '矢', '矣', '知', '矬', '短', '石', '矶', '矿', '码', '砂', '研', '砕', '砖', '砲', '破', '砸', '硝', '硬', '确', '碍', '碎', '碑', '碗', '碟', '碧', '碩', '碭', '碰', '確', '碼', '碾', '磁', '磄', '磊', '磕', '磚', '磨', '磬', '礁', '礎', '礙', '礦', '示', '礻', '礼', '社', '祀', '祁', '祂', '祈', '祐', '祕', '祖', '祗', '祜', '祝', '神', '祟', '祠', '祥', '票', '祭', '祸', '祺', '祿', '禁', '禄', '禅', '禍', '禎', '福', '禖', '禘', '禦', '禧', '禪', '禮', '禹', '离', '禽', '禾', '秀', '私', '秉', '秋', '种', '科', '秒', '秘', '租', '秣', '秤', '秦', '秩', '秪', '积', '称', '移', '稀', '程', '稍', '税', '稚', '種', '稱', '稲', '稳', '稷', '稻', '稼', '稽', '稿', '穂', '穆', '積', '穎', '穗', '穢', '穩', '穴', '究', '穷', '空', '穿', '突', '窄', '窓', '窘', '窝', '窠', '窩', '窮', '窺', '竇', '竊', '立', '站', '竜', '竝', '竞', '竟', '章', '童', '竪', '竭', '端', '竴', '競', '竹', '笈', '笏', '笑', '笔', '笙', '笛', '笠', '符', '笨', '第', '笹', '筆', '筈', '等', '筋', '筐', '筒', '答', '策', '筝', '筷', '筹', '签', '简', '箇', '箋', '箒', '算', '管', '箪', '箭', '箱', '箸', '節', '範', '篇', '築', '篠', '篡', '篤', '篮', '簋', '簒', '簡', '簦', '簽', '簿', '籃', '籍', '米', '类', '籽', '粉', '粋', '粒', '粕', '粗', '粛', '粤', '粥', '粧', '粪', '粮', '粱', '粵', '粹', '粽', '精', '糊', '糕', '糖', '糞', '糟', '糧', '糬', '糯', '糸', '系', '紀', '約', '紅', '紋', '納', '紐', '純', '紗', '紘', '紙', '級', '紛', '素', '索', '紧', '紫', '累', '細', '紹', '紺', '終', '絃', '組', '経', '結', '絕', '絞', '絡', '給', '絨', '統', '絲', '絵', '絶', '綆', '綏', '經', '継', '続', '綜', '綝', '綠', '綢', '維', '綮', '綰', '綱', '網', '綺', '綽', '綾', '緊', '総', '緑', '緒', '緖', '線', '緝', '締', '緣', '編', '緩', '緯', '練', '緼', '縑', '縚', '縛', '縣', '縦', '縮', '縱', '總', '績', '繁', '繆', '繋', '織', '繞', '繡', '繩', '繭', '繰', '繼', '繽', '纂', '續', '纎', '纏', '纒', '纠', '红', '约', '级', '纪', '纳', '纵', '纷', '纸', '线', '练', '组', '细', '织', '终', '绍', '经', '结', '给', '绚', '络', '绝', '统', '绥', '继', '绪', '续', '绰', '维', '绶', '绸', '缅', '编', '缘', '缠', '缤', '缰', '缶', '缽', '罅', '网', '罔', '罕', '罗', '罠', '罪', '置', '罰', '署', '罵', '罷', '羅', '羊', '美', '群', '羨', '義', '羲', '羽', '翁', '翅', '翊', '翌', '翎', '習', '翔', '翟', '翠', '翡', '翱', '翻', '翼', '翽', '耀', '老', '考', '耄', '者', '耋', '而', '耍', '耳', '耶', '耻', '耽', '耿', '聂', '聊', '职', '联', '聖', '聚', '聞', '聪', '聯', '聰', '聲', '聴', '聶', '職', '聽', '肃', '肄', '肅', '肆', '肇', '肉', '肋', '肌', '肖', '肘', '肚', '肝', '股', '肥', '肩', '肪', '肯', '肱', '育', '肺', '肿', '胀', '胁', '胃', '胆', '背', '胎', '胖', '胜', '胞', '胡', '胭', '胯', '胱', '胴', '胸', '能', '脂', '脅', '脆', '脇', '脈', '脑', '脖', '脚', '脫', '脱', '脳', '脸', '腆', '腊', '腐', '腑', '腕', '腚', '腥', '腦', '腮', '腰', '腱', '腳', '腸', '腹', '腺', '腾', '腿', '膀', '膂', '膊', '膏', '膚', '膝', '膨', '臀', '臂', '臉', '臓', '臘', '臣', '臥', '臨', '自', '臭', '至', '致', '臺', '臼', '舅', '舆', '與', '興', '舉', '舊', '舌', '舍', '舎', '舒', '舗', '舘', '舛', '舜', '舞', '舟', '航', '般', '舰', '舶', '船', '艚', '艤', '艦', '艮', '良', '艱', '色', '艳', '艶', '艷', '艺', '艾', '节', '芋', '芑', '芒', '芙', '芜', '芝', '芟', '芥', '芦', '花', '芳', '芸', '芽', '芾', '苍', '苏', '苑', '苓', '苗', '苛', '苞', '若', '苦', '英', '苹', '茂', '范', '茄', '茉', '茎', '茨', '茫', '茶', '草', '荒', '荘', '荣', '药', '荷', '荻', '莉', '莊', '莎', '莓', '莞', '莨', '莪', '莫', '莱', '莲', '莳', '获', '莹', '菅', '菇', '菊', '菓', '菖', '菘', '菜', '菠', '菩', '華', '菰', '菲', '菸', '菻', '萃', '萄', '萌', '萍', '萝', '营', '萧', '萨', '萬', '萱', '落', '葉', '著', '葛', '葡', '葢', '董', '葦', '葫', '葬', '葱', '蒋', '蒙', '蒜', '蒡', '蒨', '蒲', '蒸', '蒼', '蒿', '蓄', '蓉', '蓋', '蓝', '蓥', '蓬', '蓮', '蔓', '蔔', '蔘', '蔡', '蔣', '蔬', '蔵', '蔺', '蔽', '蕎', '蕙', '蕡', '蕩', '蕭', '蕴', '蕾', '薄', '薇', '薔', '薛', '薩', '薫', '薬', '藁', '藉', '藍', '藎', '藏', '藝', '藤', '藥', '藪', '藴', '藺', '藻', '蘆', '蘇', '蘭', '蘿', '虎', '虑', '處', '虚', '虜', '虞', '號', '虫', '虹', '虾', '蚊', '蚓', '蚯', '蚵', '蛆', '蛇', '蛊', '蛋', '蛙', '蛛', '蛟', '蛤', '蛮', '蜀', '蜂', '蜃', '蜊', '蜍', '蜓', '蜘', '蜜', '蜡', '蜻', '蝋', '蝕', '蝗', '蝠', '蝦', '蝴', '蝶', '融', '螗', '螺', '蟆', '蟒', '蟲', '蟹', '蟻', '蟾', '血', '衆', '行', '衍', '術', '衔', '街', '衛', '衝', '衡', '衣', '补', '表', '衰', '袁', '袂', '袈', '袋', '袍', '袢', '被', '袭', '裁', '裂', '装', '裏', '裔', '裕', '裘', '裙', '補', '裟', '裡', '裤', '裴', '裸', '製', '褁', '複', '褚', '褣', '襄', '襟', '襦', '襲', '西', '要', '覆', '覇', '見', '規', '視', '覚', '覧', '親', '覯', '観', '覺', '覽', '觀', '见', '观', '规', '视', '览', '觉', '觑', '角', '解', '触', '觸', '言', '訂', '計', '訊', '討', '訓', '託', '記', '訟', '訣', '訪', '設', '許', '訳', '訴', '訶', '診', '註', '証', '詐', '評', '詞', '詢', '試', '詩', '詫', '詮', '詰', '話', '該', '詳', '詹', '誇', '誉', '誌', '認', '誑', '誕', '誘', '語', '誠', '誤', '說', '説', '読', '誰', '課', '誹', '調', '諄', '談', '請', '諏', '諒', '論', '諗', '諜', '諦', '諫', '諶', '諷', '諸', '諾', '謀', '謂', '謎', '謗', '謙', '講', '謝', '謳', '證', '識', '譚', '譜', '警', '譬', '譯', '議', '譲', '護', '讀', '讃', '變', '讐', '讓', '讠', '计', '认', '讨', '让', '训', '议', '讯', '记', '许', '论', '设', '访', '诀', '证', '评', '识', '诉', '词', '译', '试', '诗', '诚', '诛', '话', '诡', '询', '该', '详', '语', '诱', '说', '请', '诺', '读', '谁', '调', '谈', '谊', '谋', '谐', '谓', '谢', '谦', '谱', '谷', '豆', '豈', '豉', '豊', '豎', '豐', '豚', '象', '豪', '豫', '豬', '豹', '貉', '貌', '貍', '貓', '貞', '負', '財', '貢', '貧', '貨', '販', '貪', '貫', '責', '貯', '貰', '貴', '買', '費', '貼', '貿', '賀', '資', '賈', '賊', '賓', '賛', '賜', '賞', '賠', '賢', '賣', '賤', '賦', '質', '賭', '賴', '購', '賽', '贄', '贅', '贏', '贝', '财', '责', '败', '货', '质', '贪', '贫', '贴', '贵', '贸', '费', '贺', '贼', '贾', '资', '赌', '赐', '赔', '赛', '赞', '赠', '赢', '赣', '赤', '赦', '走', '赴', '赵', '起', '趁', '超', '越', '趙', '趟', '趣', '足', '趾', '跃', '跅', '跌', '跍', '跑', '距', '跟', '跡', '跨', '跪', '路', '跳', '踉', '踊', '踏', '踝', '踢', '踪', '踵', '蹀', '蹋', '蹤', '蹲', '蹴', '蹶', '躅', '躍', '躑', '身', '躲', '車', '軌', '軍', '軒', '軟', '転', '軽', '較', '載', '輔', '輕', '輝', '輟', '輩', '輪', '輯', '輸', '輿', '轄', '轆', '轉', '轍', '轟', '轤', '车', '转', '轮', '软', '轰', '轶', '轻', '载', '辆', '辈', '辉', '辐', '辑', '输', '辖', '辛', '辜', '辞', '辣', '辦', '辨', '辭', '辯', '辰', '辱', '農', '辶', '辺', '込', '辽', '达', '辿', '迄', '迅', '过', '迈', '迎', '运', '近', '返', '还', '这', '进', '远', '连', '迟', '迦', '迪', '迫', '迭', '述', '迷', '追', '退', '送', '适', '逃', '逅', '逆', '逈', '选', '透', '递', '途', '逗', '這', '通', '速', '造', '逢', '連', '逮', '週', '進', '逸', '逼', '遁', '遂', '遅', '遇', '遊', '運', '遍', '過', '遏', '道', '達', '違', '遗', '遙', '遠', '遣', '遥', '適', '遭', '遮', '遯', '遲', '遵', '遷', '選', '遺', '遼', '避', '邀', '邂', '邃', '還', '邇', '邉', '邊', '邏', '邑', '邓', '邝', '邢', '那', '邦', '邪', '邮', '邰', '邱', '邵', '邹', '郁', '郎', '郑', '郗', '郝', '郟', '郡', '部', '郭', '郵', '郷', '都', '鄂', '鄉', '鄒', '鄔', '鄕', '鄘', '鄞', '鄢', '鄧', '鄭', '鄺', '酆', '酈', '酉', '酊', '酌', '配', '酎', '酒', '酔', '酢', '酥', '酬', '酱', '酲', '酵', '酷', '酸', '酿', '醉', '醋', '醒', '醞', '醢', '醣', '醫', '醬', '醴', '醵', '醺', '釀', '釆', '采', '釈', '釋', '里', '重', '野', '量', '釐', '金', '釗', '釜', '針', '釣', '釦', '鈍', '鈎', '鈕', '鈴', '鉄', '鉗', '鉛', '鉞', '鉢', '鉤', '銀', '銃', '銅', '銕', '銘', '銭', '銳', '鋒', '鋤', '鋪', '鋭', '鋳', '鋼', '錄', '錠', '錢', '錦', '錨', '錫', '錯', '録', '鍊', '鍋', '鍚', '鍛', '鍭', '鍵', '鍾', '鎊', '鎌', '鎖', '鎗', '鎚', '鎧', '鎬', '鎮', '鏃', '鏑', '鏗', '鏞', '鏡', '鐘', '鐙', '鐮', '鐵', '鑑', '鑠', '鑽', '针', '钓', '钟', '钢', '钥', '钰', '钱', '钻', '铁', '铃', '铊', '铜', '铭', '银', '铺', '链', '销', '锁', '锅', '锋', '错', '锡', '锤', '锥', '锦', '锭', '键', '镇', '镛', '镜', '長', '长', '門', '閂', '閃', '閉', '開', '閏', '間', '閔', '関', '閣', '閭', '閱', '闇', '闕', '闘', '關', '门', '闪', '问', '间', '闵', '闹', '闻', '闽', '阁', '阅', '队', '阪', '阮', '防', '阳', '阴', '阵', '阶', '阻', '阿', '陀', '附', '际', '陆', '陈', '降', '限', '陕', '陛', '陝', '院', '陣', '除', '陥', '险', '陪', '陰', '陳', '陵', '陶', '陷', '陸', '険', '陽', '隆', '隈', '隊', '隋', '隍', '階', '随', '隐', '隔', '際', '障', '隠', '隣', '隨', '險', '隱', '隶', '隷', '隸', '隻', '难', '雀', '雁', '雄', '雅', '集', '雇', '雉', '雌', '雎', '雑', '雖', '雙', '雛', '雜', '雞', '離', '難', '雨', '雪', '雫', '雯', '雰', '雲', '零', '雷', '電', '需', '震', '霊', '霍', '霖', '霜', '霞', '霧', '露', '霸', '霹', '靂', '靈', '靑', '青', '靖', '静', '靜', '非', '靠', '面', '靣', '革', '靴', '鞋', '鞍', '鞏', '鞭', '韃', '韋', '韓', '韜', '韩', '音', '響', '頁', '頂', '頃', '項', '順', '須', '頊', '頌', '預', '頑', '頓', '頗', '領', '頤', '頭', '頸', '頹', '頼', '題', '額', '顏', '顓', '顔', '願', '類', '顧', '顯', '页', '顶', '项', '顺', '须', '顾', '领', '颇', '颈', '频', '颖', '颗', '题', '颜', '额', '颠', '颧', '風', '飄', '风', '飘', '飛', '飜', '飞', '食', '飩', '飯', '飲', '飼', '飽', '飾', '餃', '餅', '養', '餐', '餘', '餛', '餠', '館', '餮', '饅', '饒', '饕', '饭', '饮', '饺', '饼', '馆', '馋', '馍', '馒', '首', '馗', '香', '馨', '馬', '馭', '馮', '馴', '駄', '駅', '駆', '駐', '駒', '駕', '駢', '駱', '駿', '騎', '騒', '験', '騰', '驅', '驚', '驪', '马', '驱', '驴', '驶', '驾', '验', '骐', '骑', '骥', '骨', '骸', '髄', '體', '高', '髪', '髭', '髮', '鬆', '鬘', '鬚', '鬥', '鬭', '鬻', '鬼', '魁', '魂', '魄', '魅', '魇', '魏', '魔', '魚', '魯', '魷', '鮓', '鮨', '鮭', '鮮', '鯀', '鯉', '鯨', '鰈', '鰓', '鰲', '鰻', '鱉', '鱔', '鱗', '鱷', '鱼', '鱿', '鲁', '鲜', '鲤', '鲨', '鳌', '鳙', '鳥', '鳦', '鳩', '鳳', '鳴', '鴉', '鴛', '鴦', '鴨', '鵜', '鵞', '鵠', '鵬', '鶏', '鶴', '鶻', '鷲', '鷹', '鷺', '鸂', '鸞', '鸟', '鸡', '鸣', '鸭', '鸯', '鸳', '鸵', '鸿', '鹅', '鹊', '鹌', '鹏', '鹑', '鹤', '鹭', '鹰', '鹳', '鹹', '鹽', '鹿', '麄', '麒', '麗', '麟', '麥', '麦', '麩', '麵', '麸', '麺', '麻', '麼', '黃', '黄', '黎', '黑', '黒', '黔', '默', '黙', '點', '黟', '黨', '黻', '鼎', '鼓', '鼠', '鼬', '鼻', '齊', '齋', '齐', '齢', '齪', '齷', '齿', '龄', '龍', '龐', '龔', '龙', '龚', '龟', 'ꜜ', 'ꜣ', 'ꭰ', 'ꭱ', 'ꭲ', 'ꭳ', 'ꭴ', 'ꭵ', 'ꭶ', 'ꭷ', 'ꭸ', 'ꭹ', 'ꭺ', 'ꭻ', 'ꭼ', 'ꭽ', 'ꭾ', 'ꭿ', 'ꮀ', 'ꮁ', 'ꮂ', 'ꮃ', 'ꮄ', 'ꮅ', 'ꮆ', 'ꮇ', 'ꮈ', 'ꮉ', 'ꮊ', 'ꮋ', 'ꮌ', 'ꮍ', 'ꮎ', 'ꮏ', 'ꮐ', 'ꮑ', 'ꮒ', 'ꮓ', 'ꮔ', 'ꮕ', 'ꮖ', 'ꮗ', 'ꮘ', 'ꮙ', 'ꮚ', 'ꮛ', 'ꮜ', 'ꮝ', 'ꮞ', 'ꮟ', 'ꮠ', 'ꮡ', 'ꮢ', 'ꮣ', 'ꮤ', 'ꮥ', 'ꮦ', 'ꮧ', 'ꮨ', 'ꮩ', 'ꮪ', 'ꮫ', 'ꮬ', 'ꮭ', 'ꮮ', 'ꮯ', 'ꮰ', 'ꮱ', 'ꮲ', 'ꮳ', 'ꮴ', 'ꮵ', 'ꮶ', 'ꮷ', 'ꮸ', 'ꮹ', 'ꮺ', 'ꮻ', 'ꮼ', 'ꮽ', 'ꮾ', 'ꮿ', '가', '각', '간', '갈', '감', '갑', '갔', '강', '갖', '같', '갚', '개', '객', '갱', '갹', '걔', '거', '걱', '건', '걷', '걸', '검', '것', '게', '겟', '겠', '겨', '격', '겪', '견', '결', '겸', '겹', '겼', '경', '계', '고', '곡', '골', '곳', '공', '곶', '과', '곽', '관', '광', '괜', '괴', '굉', '교', '구', '국', '군', '굴', '굿', '궁', '권', '귀', '규', '귤', '그', '극', '근', '귿', '글', '금', '급', '기', '긴', '길', '김', '깊', '까', '깎', '깐', '깔', '깜', '깝', '깨', '꺼', '께', '껴', '꼈', '꼬', '꼭', '꼴', '꼽', '꽁', '꽃', '꽤', '꾀', '꾸', '꾼', '꿀', '꿈', '꿉', '꿨', '끄', '끈', '끊', '끌', '끗', '끝', '끼', '낀', '낄', '낌', '나', '낙', '난', '날', '남', '낫', '났', '낭', '낮', '낯', '내', '낸', '낼', '냈', '냉', '냐', '냥', '너', '널', '넓', '넘', '네', '넷', '녀', '년', '념', '녕', '노', '녹', '논', '놀', '놈', '농', '높', '놓', '놨', '뇌', '누', '눈', '뉴', '느', '늑', '는', '늘', '능', '늦', '늬', '니', '닉', '닌', '닐', '님', '닙', '닛', '닝', '다', '닥', '단', '닫', '달', '담', '답', '닷', '당', '대', '댄', '댓', '댕', '댤', '더', '덕', '던', '덧', '데', '덴', '델', '도', '독', '돈', '돋', '돌', '돔', '돕', '동', '돼', '됐', '되', '된', '될', '됨', '됩', '두', '둘', '둥', '뒀', '뒤', '뒷', '듀', '드', '득', '든', '듣', '들', '듬', '듯', '등', '디', '딩', '따', '딱', '딸', '땄', '땅', '때', '땐', '땡', '떠', '떡', '떤', '떨', '떻', '뗐', '또', '똑', '뚜', '뚫', '뛰', '뜨', '뜻', '띄', '라', '락', '란', '랄', '람', '랍', '랐', '랑', '래', '랙', '랜', '램', '랩', '랫', '랬', '랭', '략', '량', '러', '런', '럴', '럼', '럽', '럿', '렀', '렇', '레', '렌', '렛', '려', '력', '련', '렵', '렷', '렸', '령', '례', '로', '록', '론', '롭', '롯', '료', '룡', '루', '룩', '룰', '룹', '뤄', '류', '르', '른', '를', '름', '릉', '리', '릭', '린', '릴', '림', '립', '링', '마', '막', '만', '많', '맏', '말', '맘', '맙', '맛', '망', '맞', '맡', '매', '맥', '맵', '머', '먹', '먼', '멅', '멈', '멋', '메', '멘', '멜', '멤', '며', '면', '명', '몇', '몌', '모', '목', '몫', '몬', '몰', '몸', '못', '몽', '묘', '무', '묶', '문', '묻', '물', '뭇', '뭐', '뭔', '뮤', '므', '미', '믹', '민', '믿', '밀', '밍', '및', '바', '박', '밖', '반', '받', '발', '밝', '밤', '밥', '방', '배', '백', '밴', '밸', '뱀', '뱃', '뱅', '버', '번', '벌', '범', '법', '벗', '벚', '베', '벨', '벳', '벽', '변', '별', '병', '보', '복', '본', '볼', '봇', '봉', '봐', '봤', '부', '북', '분', '불', '붉', '붐', '붕', '붙', '뷔', '뷰', '브', '블', '비', '빈', '빌', '빔', '빕', '빗', '빙', '빚', '빛', '빠', '빨', '빵', '빼', '뺨', '뻐', '뻘', '뽀', '뽈', '뽑', '뽕', '뿌', '뿐', '쁘', '쁜', '삐', '사', '삭', '산', '살', '삶', '삼', '샀', '상', '새', '색', '생', '샤', '샵', '서', '석', '선', '설', '섬', '섭', '섯', '섰', '성', '세', '섹', '센', '셈', '셉', '셋', '셔', '션', '셧', '셨', '소', '속', '손', '솔', '송', '쇄', '쇼', '수', '숙', '순', '술', '숨', '숲', '쉐', '쉬', '쉴', '쉽', '슈', '슐', '스', '슨', '슬', '습', '슷', '승', '시', '식', '신', '실', '싫', '심', '십', '싱', '싶', '싸', '쌍', '쌓', '써', '썬', '썹', '썼', '쏘', '쏟', '쑤', '쓰', '쓴', '쓸', '씨', '씩', '씬', '씹', '아', '악', '안', '않', '알', '앓', '암', '압', '앗', '았', '앙', '앞', '애', '앤', '앨', '야', '약', '양', '얘', '어', '억', '언', '얻', '얼', '엄', '업', '없', '엇', '었', '에', '엑', '엔', '엘', '엠', '여', '역', '연', '열', '엽', '였', '영', '옆', '예', '옛', '오', '옥', '온', '올', '옳', '옷', '옹', '와', '완', '왔', '왕', '왜', '왠', '외', '왼', '요', '욕', '용', '우', '욱', '운', '울', '움', '웃', '웅', '워', '원', '월', '웨', '웹', '위', '윗', '유', '육', '윤', '율', '융', '으', '윽', '은', '읃', '을', '음', '읍', '읏', '응', '읒', '의', '이', '익', '인', '일', '읽', '잃', '임', '입', '있', '잉', '잊', '잎', '자', '작', '잔', '잖', '잘', '잠', '잡', '장', '재', '잭', '쟁', '저', '적', '전', '젇', '절', '젊', '점', '접', '젓', '정', '제', '젝', '젠', '져', '졌', '조', '족', '존', '졸', '좀', '좃', '종', '좋', '좌', '죄', '죠', '죤', '주', '죽', '준', '줄', '줌', '중', '줘', '줬', '즈', '즉', '즌', '즐', '즘', '증', '지', '직', '진', '질', '짐', '집', '짓', '징', '짙', '짜', '짝', '짧', '짬', '짱', '째', '쩄', '쩌', '쪽', '쭘', '쯔', '찌', '찍', '찜', '차', '착', '찬', '찮', '찰', '참', '창', '찾', '채', '책', '챙', '처', '척', '천', '철', '첨', '첫', '청', '체', '쳐', '쳤', '초', '촌', '총', '촬', '최', '추', '축', '출', '춤', '충', '춰', '취', '츄', '츠', '측', '층', '치', '칙', '친', '칠', '침', '카', '칼', '캐', '캔', '캡', '커', '컨', '컬', '컴', '컷', '케', '켓', '켜', '켰', '코', '콘', '콜', '콤', '쾌', '쿠', '쿨', '퀴', '큐', '크', '큰', '클', '큼', '키', '킥', '킨', '킬', '킵', '킸', '킹', '타', '탁', '탄', '탈', '탑', '탕', '태', '택', '터', '턱', '턴', '털', '테', '텐', '텔', '템', '토', '톤', '톰', '통', '퇴', '투', '튄', '튜', '트', '특', '튿', '틀', '티', '틱', '팀', '팅', '파', '판', '팔', '팝', '패', '팩', '팬', '퍼', '펑', '페', '펠', '펴', '편', '펼', '평', '폐', '포', '폭', '폰', '폴', '폼', '표', '푸', '풀', '품', '풍', '프', '픈', '플', '피', '핀', '필', '핑', '하', '학', '한', '할', '함', '합', '핫', '항', '해', '핸', '했', '행', '향', '허', '험', '헛', '헤', '헬', '헷', '혀', '혁', '현', '혈', '협', '혔', '형', '혜', '호', '혹', '혼', '홈', '홉', '홍', '화', '확', '환', '활', '황', '회', '획', '횟', '효', '후', '훈', '휘', '휩', '휴', '흐', '흑', '흔', '흘', '흙', '흥', '흩', '희', '히', '힌', '힐', '힘', '힙', '\\ue000', '\\ue001', '\\ue002', '\\ue003', '\\ue004', '\\ue005', '\\ue006', '\\ue007', '\\ue008', '\\ue009', '\\ue00a', '\\ue00c', '\\ue00d', '\\ue00e', '\\ue012', '\\ue014', '\\ue017', '\\ue018', '\\ue01a', '\\ue01c', '\\ue01e', '\\ue01f', '\\ue020', '\\ue021', '\\ue022', '\\ue024', '\\ue025', '\\ue028', '\\ue029', '\\ue02a', '\\ue02c', '\\ue02d', '\\ue02e', '\\ue02f', '\\ue030', '\\ue031', '\\ue032', '\\ue034', '\\ue036', '\\ue039', '\\ue03a', '\\ue03c', '\\ue057', '\\ue05f', '\\ue061', '\\ue062', '\\ue063', '\\ue064', '\\ue065', '\\ue066', '\\ue067', '\\ue068', '\\ue069', '\\ue06a', '\\ue06b', '\\ue06c', '\\ue06e', '\\ue06f', '\\ue070', '\\ue071', '\\ue072', '\\ue073', '\\ue074', '\\ue075', '\\ue078', '\\ue079', '\\ue07a', '\\ue07b', '\\ue07d', '\\ue084', '\\ue085', '\\ue147', '\\ue2f6', '\\ue2fa', '\\ue602', '\\ue605', '\\ue606', '\\ue607', '\\ue60c', '\\ue60e', '\\ue610', '\\ue617', '\\ue61a', '\\ue61c', '\\ue61d', '\\ue624', '\\ue631', '\\ue632', '\\ue637', '\\ue63e', '\\ue648', '\\ue64f', '\\ue650', '\\ue75a', '\\ue800', '\\ue801', '\\ue803', '\\ue804', '\\ue805', '\\ue806', '\\ue808', '\\ue809', '\\ue80a', '\\ue80b', '\\ue80d', '\\ue80e', '\\ue80f', '\\ue810', '\\ue811', '\\ue816', '\\ue817', '\\ue818', '\\ue81b', '\\ue81c', '\\ue81e', '\\ue822', '\\ue838', '\\ue842', '\\ue872', '\\uea22', '\\uea24', '\\uea2e', '\\uea34', '\\uea42', '\\uea71', '\\uea86', '\\uea8a', '\\ued61', '\\uefff', '\\uf00d', '\\uf00e', '\\uf020', '\\uf02f', '\\uf030', '\\uf046', '\\uf04a', '\\uf04b', '\\uf054', '\\uf055', '\\uf057', '\\uf061', '\\uf064', '\\uf065', '\\uf067', '\\uf069', '\\uf06b', '\\uf06d', '\\uf06e', '\\uf06f', '\\uf072', '\\uf073', '\\uf076', '\\uf077', '\\uf07a', '\\uf082', '\\uf086', '\\uf096', '\\uf099', '\\uf09a', '\\uf09f', '\\uf0b0', '\\uf0b7', '\\uf0b8', '\\uf0be', '\\uf0c0', '\\uf0d2', '\\uf0d5', '\\uf0d9', '\\uf0da', '\\uf0e0', '\\uf101', '\\uf104', '\\uf105', '\\uf106', '\\uf107', '\\uf108', '\\uf10a', '\\uf10c', '\\uf10d', '\\uf10e', '\\uf111', '\\uf11d', '\\uf11e', '\\uf121', '\\uf130', '\\uf141', '\\uf145', '\\uf146', '\\uf1f5', '\\uf1f9', '\\uf30f', '\\uf312', '\\uf32e', '\\uf44f', '\\uf4f0', '\\uf500', '\\uf610', '\\uf611', '\\uf613', '\\uf633', '\\uf650', '\\uf702', '\\uf7df', '\\uf8fe', '\\uf8ff', 'ﬀ', 'ﬁ', 'ﬂ', 'ﬃ', 'ﬄ', 'ﬅ', 'ﬆ', 'ﮌ', '﴾', '﴿', 'ﷺ', 'ﷻ', '﷼', '﷽', '︁', '︎', '️', '︵', '︶', '︷', '︻', '︿', '﹏', 'ﺂ', 'ﺑ', 'ﺡ', 'ﺤ', 'ﺩ', 'ﺮ', 'ﺯ', 'ﺳ', 'ﻋ', 'ﻜ', 'ﻟ', 'ﻢ', 'ﻣ', 'ﻦ', 'ﻭ', 'ﻳ', 'ﻷ', 'ﻹ', '\\ufeff', '！', '＂', '＃', '％', '＆', '（', '）', '＊', '＋', '，', '－', '．', '／', '０', '１', '２', '３', '４', '５', '６', '７', '８', '９', '：', '；', '＜', '＝', '＞', '？', '＠', 'Ａ', 'Ｂ', 'Ｃ', 'Ｄ', 'Ｅ', 'Ｆ', 'Ｇ', 'Ｈ', 'Ｉ', 'Ｊ', 'Ｋ', 'Ｌ', 'Ｍ', 'Ｎ', 'Ｏ', 'Ｐ', 'Ｑ', 'Ｒ', 'Ｓ', 'Ｔ', 'Ｕ', 'Ｖ', 'Ｗ', 'Ｘ', 'Ｙ', 'Ｚ', '［', '＼', '］', '＾', '＿', '｀', 'ａ', 'ｂ', 'ｃ', 'ｄ', 'ｅ', 'ｆ', 'ｇ', 'ｈ', 'ｉ', 'ｊ', 'ｋ', 'ｌ', 'ｍ', 'ｎ', 'ｏ', 'ｐ', 'ｑ', 'ｒ', 'ｓ', 'ｔ', 'ｕ', 'ｖ', 'ｗ', 'ｘ', 'ｙ', 'ｚ', '｜', '～', '｡', '｢', '｣', '､', '･', 'ｦ', 'ｧ', 'ｨ', 'ｩ', 'ｪ', 'ｫ', 'ｬ', 'ｭ', 'ｮ', 'ｯ', 'ｰ', 'ｱ', 'ｲ', 'ｳ', 'ｴ', 'ｵ', 'ｶ', 'ｷ', 'ｸ', 'ｹ', 'ｺ', 'ｻ', 'ｼ', 'ｽ', 'ｾ', 'ｿ', 'ﾀ', 'ﾁ', 'ﾂ', 'ﾃ', 'ﾄ', 'ﾅ', 'ﾆ', 'ﾇ', 'ﾈ', 'ﾉ', 'ﾊ', 'ﾋ', 'ﾌ', 'ﾍ', 'ﾎ', 'ﾏ', 'ﾐ', 'ﾑ', 'ﾒ', 'ﾓ', 'ﾔ', 'ﾕ', 'ﾖ', 'ﾗ', 'ﾘ', 'ﾙ', 'ﾚ', 'ﾛ', 'ﾜ', 'ﾝ', 'ﾞ', 'ﾟ', 'ﾠ', 'ﾣ', 'ﾦ', 'ﾧ', 'ﾩ', 'ﾮ', 'ﾳ', 'ﾴ', 'ﾵ', 'ﾸ', 'ﾻ', 'ﾼ', 'ﾽ', 'ﾾ', '\\uffbf', 'ￃ', '￡', '￣', '￥', '￦', '\\ufff0', '￼', '�', '𐀇', '𐀝', '𐀰', '𐀺', '𐎡', '𐎦', '𐎲', '𐑐', '𐑑', '𐑒', '𐑓', '𐑔', '𐑕', '𐑖', '𐑗', '𐑘', '𐑙', '𐑚', '𐑛', '𐑜', '𐑝', '𐑞', '𐑟', '𐑠', '𐑡', '𐑢', '𐑣', '𐑤', '𐑥', '𐑦', '𐑧', '𐑨', '𐑩', '𐑪', '𐑫', '𐑬', '𐑭', '𐑮', '𐑯', '𐑰', '𐑱', '𐑲', '𐑳', '𐑴', '𐑵', '𐑶', '𐑷', '𐑸', '𐑹', '𐑺', '𐑻', '𐑼', '𐑽', '𐑾', '𐑿', '𐤀', '𐤁', '𐤂', '𐤃', '𐤋', '𐤒', '𐤔', '𒀀', '𒀉', '𒀊', '𒀖', '𒀜', '𒀝', '𒀞', '𒀠', '𒀩', '𒀭', '𒀸', '𒀹', '𒀺', '𒀾', '𒁀', '𒁁', '𒁉', '𒁍', '𒁕', '𒁲', '𒁴', '𒁹', '𒁺', '𒁽', '𒂆', '𒂊', '𒂍', '𒂔', '𒂖', '𒂗', '𒂠', '𒂵', '𒂷', '𒃶', '𒄀', '𒄄', '𒄉', '𒄑', '𒄖', '𒄘', '𒄞', '𒄠', '𒄩', '𒄭', '𒄴', '𒄷', '𒄿', '𒅁', '𒅅', '𒅆', '𒅇', '𒅈', '𒅋', '𒅍', '𒅎', '𒅔', '𒅕', '𒅖', '𒅗', '𒅘', '𒅠', '𒅤', '𒅥', '𒅬', '𒆍', '𒆕', '𒆜', '𒆠', '𒆤', '𒆪', '𒆬', '𒆭', '𒆷', '𒇉', '𒇥', '𒇲', '𒇷', '𒇻', '𒇽', '𒈠', '𒈣', '𒈦', '𒈨', '𒈩', '𒈪', '𒈬', '𒈾', '𒈿', '𒉈', '𒉌', '𒉎', '𒉘', '𒉡', '𒉺', '𒉿', '𒊌', '𒊍', '𒊏', '𒊑', '𒊒', '𒊓', '𒊕', '𒊩', '𒊬', '𒊭', '𒊮', '𒊹', '𒊺', '𒋀', '𒋗', '𒋙', '𒋛', '𒋜', '𒋢', '𒋤', '𒋫', '𒋼', '𒋾', '𒌅', '𒌆', '𒌈', '𒌋', '𒌌', '𒌍', '𒌑', '𒌒', '𒌓', '𒌔', '𒌝', '𒌦', '𒌨', '𒌫', '𒌵', '𒌷', '𒍑', '𒍗', '𒍚', '𒍝', '𒍢', '𒍣', '𒍥', '𒍪', '𒐀', '𒐁', '𒐊', '𒐼', '𓃀', '𓅓', '𓈉', '𓈖', '𓎡', '𛀀', '𛀁', '𛀂', '𛀃', '𛀄', '𛀅', '𛀆', '𛀇', '𛀈', '𛀉', '𛀊', '𛀋', '𛀌', '𛀍', '𛀎', '𛀏', '𛀐', '𛀑', '𛀒', '𛀓', '𛀔', '𛀕', '𛀖', '𛀗', '𛀘', '𛀙', '𛀚', '𛀛', '𛀜', '𛀝', '𛀞', '𛀟', '𛀠', '𛀡', '𛀢', '𛀣', '𛀤', '𛀥', '𛀦', '𛀧', '𛀨', '𛀩', '𛀪', '𛀫', '𛀬', '𛀭', '𛀮', '𛀯', '𛀰', '𛀱', '𛀲', '𛀳', '𛀴', '𛀵', '𛀶', '𛀷', '𛀸', '𛀹', '𛀺', '𛀻', '𛀼', '𛀽', '𛀾', '𛀿', '𛁀', '𛁁', '𛁂', '𛁃', '𛁄', '𛁅', '𛁆', '𛁇', '𛁈', '𛁉', '𛁊', '𛁋', '𛁌', '𛁍', '𛁎', '𛁏', '𛁐', '𛁑', '𛁒', '𛁓', '𛁔', '𛁕', '𛁖', '𛁗', '𛁘', '𛁙', '𛁚', '𛁛', '𛁜', '𛁝', '𛁞', '𛁟', '𛁠', '𛁡', '𛁢', '𛁣', '𛁤', '𛁥', '𛁦', '𛁧', '𛁨', '𛁩', '𛁪', '𛁫', '𛁬', '𛁭', '𛁮', '𛁯', '𛁰', '𛁱', '𛁲', '𛁳', '𛁴', '𛁵', '𛁶', '𛁷', '𛁸', '𛁹', '𛁺', '𛁻', '𛁼', '𛁽', '𛁾', '𛁿', '𛂀', '𛂁', '𛂂', '𛂃', '𛂄', '𛂅', '𛂆', '𛂇', '𛂈', '𛂉', '𛂊', '𛂋', '𛂌', '𛂍', '𛂎', '𛂏', '𛂐', '𛂑', '𛂒', '𛂓', '𛂔', '𛂕', '𛂖', '𛂗', '𛂘', '𛂙', '𛂚', '𛂛', '𛂜', '𛂝', '𛂞', '𛂟', '𛂠', '𛂡', '𛂢', '𛂣', '𛂤', '𛂥', '𛂦', '𛂧', '𛂨', '𛂩', '𛂪', '𛂫', '𛂬', '𛂭', '𛂮', '𛂯', '𛂰', '𛂱', '𛂲', '𛂳', '𛂴', '𛂵', '𛂶', '𛂷', '𛂸', '𛂹', '𛂺', '𛂻', '𛂼', '𛂽', '𛂾', '𛂿', '𛃀', '𛃁', '𛃂', '𛃃', '𛃄', '𛃅', '𛃆', '𛃇', '𛃈', '𛃉', '𛃊', '𛃋', '𛃌', '𛃍', '𛃎', '𛃏', '𛃐', '𛃑', '𛃒', '𛃓', '𛃔', '𛃕', '𛃖', '𛃗', '𛃘', '𛃙', '𛃚', '𛃛', '𛃜', '𛃝', '𛃞', '𛃟', '𛃠', '𛃡', '𛃢', '𛃣', '𛃤', '𛃥', '𛃦', '𛃧', '𛃨', '𛃩', '𛃪', '𛃫', '𛃬', '𛃭', '𛃮', '𛃯', '𛃰', '𛃱', '𛃲', '𛃳', '𛃴', '𛃵', '𛃶', '𛃷', '𛃸', '𛃹', '𛃺', '𛃻', '𛃼', '𛃽', '𛃾', '𛃿', '𝄆', '𝄇', '𝄞', '𝐂', '𝐄', '𝐅', '𝐈', '𝐌', '𝐍', '𝐑', '𝐓', '𝐼', '𝑃', '𝑒', '𝑙', '𝑛', '𝑫', '𝑰', '𝑾', '𝒂', '𝒅', '𝒉', '𝒏', '𝒐', '𝒓', '𝒕', '𝒘', '𝒦', '𝒾', '𝓃', '𝓉', '𝓓', '𝓗', '𝓛', '𝓞', '𝔉', '𝔼', '𝕭', '𝖄', '𝖆', '𝖈', '𝖙', '𝙸', '𝛳', '𝛽', '𝜑', '𝝎', '🂠', '🅥', '🅱', '🅿', '🆒', '🆕', '🇦', '🇧', '🇨', '🇩', '🇪', '🇫', '🇬', '🇭', '🇮', '🇯', '🇰', '🇱', '🇲', '🇳', '🇴', '🇵', '🇶', '🇷', '🇸', '🇹', '🇺', '🇻', '🇼', '🇽', '🌄', '🌇', '🌈', '🌊', '🌌', '🌍', '🌎', '🌏', '🌐', '🌒', '🌙', '🌞', '🌟', '🌤', '🌧', '🌪', '🌭', '🌮', '🌱', '🌲', '🌳', '🌴', '🌶', '🌸', '🌹', '🌺', '🌻', '🌾', '🍁', '🍃', '🍄', '🍆', '🍉', '🍌', '🍍', '🍎', '🍐', '🍑', '🍒', '🍔', '🍕', '🍗', '🍦', '🍩', '🍪', '🍯', '🍰', '🍳', '🍷', '🍸', '🍹', '🍺', '🍻', '🍼', '🍾', '🍿', '🎀', '🎁', '🎂', '🎃', '🎄', '🎅', '🎆', '🎇', '🎈', '🎉', '🎊', '🎒', '🎓', '🎙', '🎛', '🎡', '🎣', '🎤', '🎥', '🎧', '🎨', '🎩', '🎬', '🎮', '🎯', '🎲', '🎵', '🎶', '🎸', '🎾', '🏀', '🏁', '🏃', '🏄', '🏆', '🏈', '🏊', '🏌', '🏎', '🏒', '🏓', '🏖', '🏞', '🏦', '🏮', '🏳', '🏻', '🏼', '🏽', '🏾', '🏿', '🐀', '🐁', '🐃', '🐅', '🐊', '🐋', '🐐', '🐔', '🐘', '🐙', '🐚', '🐛', '🐜', '🐝', '🐢', '🐣', '🐤', '🐥', '🐦', '🐧', '🐩', '🐬', '🐰', '🐱', '🐴', '🐶', '🐷', '🐸', '🐻', '🐾', '👀', '👁', '👂', '👃', '👅', '👇', '👈', '👉', '👊', '👋', '👌', '👍', '👎', '👏', '👑', '👙', '👜', '👟', '👦', '👧', '👨', '👩', '👬', '👭', '👮', '👯', '👱', '👳', '👴', '👶', '👸', '👹', '👺', '👻', '👼', '👽', '👾', '👿', '💀', '💁', '💃', '💄', '💅', '💈', '💉', '💊', '💋', '💌', '💍', '💎', '💔', '💕', '💖', '💗', '💙', '💚', '💛', '💜', '💝', '💞', '💡', '💢', '💣', '💥', '💦', '💨', '💩', '💪', '💫', '💬', '💭', '💯', '💰', '💱', '💳', '💵', '💷', '💸', '💹', '💻', '💿', '📀', '📃', '📅', '📈', '📉', '📊', '📍', '📓', '📖', '📘', '📚', '📝', '📡', '📢', '📣', '📦', '📧', '📩', '📮', '📯', '📰', '📱', '📲', '📷', '📸', '📹', '📺', '📻', '🔇', '🔈', '🔊', '🔋', '🔍', '🔎', '🔑', '🔒', '🔓', '🔔', '🔗', '🔘', '🔙', '🔥', '🔨', '🔪', '🔫', '🔬', '🔮', '🔰', '🔱', '🔴', '🔵', '🔶', '🔷', '🔹', '🕊', '🕋', '🕯', '🕴', '🕺', '🖊', '🖋', '🖕', '🖖', '🖤', '🖥', '🗒', '🗓', '🗞', '🗡', '🗣', '🗯', '🗳', '🗺', '🗽', '😀', '😁', '😂', '😃', '😄', '😅', '😆', '😇', '😈', '😉', '😊', '😋', '😍', '😎', '😏', '😐', '😑', '😒', '😓', '😔', '😕', '😖', '😘', '😛', '😜', '😝', '😞', '😟', '😠', '😡', '😢', '😣', '😤', '😥', '😦', '😨', '😩', '😫', '😬', '😭', '😮', '😯', '😰', '😱', '😲', '😳', '😴', '😵', '😷', '😺', '😼', '🙀', '🙁', '🙂', '🙃', '🙄', '🙅', '🙆', '🙇', '🙈', '🙊', '🙌', '🙏', '🚀', '🚁', '🚂', '🚇', '🚊', '🚒', '🚗', '🚙', '🚚', '🚤', '🚨', '🚩', '🚫', '🚮', '🚵', '🚶', '🚽', '🛐', '🛠', '🛬', '🛳', '🤐', '🤑', '🤒', '🤓', '🤔', '🤕', '🤖', '🤗', '🤘', '🤙', '🤠', '🤡', '🤢', '🤣', '🤤', '🤥', '🤦', '🤩', '🤭', '🤯', '🤳', '🤷', '🥁', '🥃', '🥄', '🥅', '🥑', '🥛', '🦀', '🦁', '🦂', '🦃', '🦄', '🦅', '🦇', '🦉', '🦋', '🦠', '🧀', '🧥', '𠀀', '𠀁', '𠀅', '𠃉', '𠃋', '𠄎', '𠄡', '𠆢', '𠚣', '𠠲', '𠫓', '𡇒', '𡰣', '𡳿', '𡿨', '𢎘', '𦡁', '𨽾', '\\U000d0030', '\\U000f0024', '\\U000f0030', '\\U000f0031', '\\U000f0032', '\\U000f0034', '\\U000f0035', '\\U000f0037', '\\U000f0039', '\\U000f0062', '\\U000f0069', '\\U000f006e', '\\U000f0073', '\\U000fe1d7', '\\U00100031', '\\U00100032', '\\U00100033', '\\U00100034', '\\U00100036', '\\U00100037', '\\U00100038']\n",
      "10474\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "print(len(chars))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ed1e38-0a86-4d5f-9709-37f728e80628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8267,     1,  9779,     1,  6986,     1,  1428,     1,  5002,     1,\n",
      "         3360,     1,  9617,     1,  1397,     1,  5069,     1,  1956,     1,\n",
      "           15,     1,  6555,     1,  8865,     1,  4070,     1,  6153,     1,\n",
      "         7213,     1,  7754,     1,  3121,     1,  5465,     1,  4918,     1,\n",
      "        10103,     1,  7517,     1, 10209,     1,  5499,     1,  5813,     1,\n",
      "         2244,     1,  5713,     1,  6202,     1,  8216,     1,  7939,     1,\n",
      "         9726,     1,  6413,     1,  5235,     1,  4885,     1,  7129,     1,\n",
      "        10224,     1,   965,     1,  5845,     1,  3040,     1,  9739,     1,\n",
      "         4313,     1,   304,     1,  9152,     1,  2233,     1,  9689,     1,\n",
      "         2972,     1,  8566,     1,  1348,     1,  6847,     1,  5008,     1,\n",
      "         1561,     1,  7919,     1,   589,     1,  5240,     1,  2753,     1,\n",
      "         2937,     1,  4709,     1,  6573,     1,  1037,     1,  1132,     1,\n",
      "         1093,     1,  7521,     1,  9939,     1,  1622,     1,  7640,     1,\n",
      "         4929,     1,  4257,     1,  3971,     1,  1713,     1,  8063,     1,\n",
      "         2239,     1,  8148,     1,  1202,     1,  6727,     1,   333,     1,\n",
      "         8310,     1,  9257,     1,  1538,     1,  3800,     1,  3155,     1,\n",
      "         2224,     1, 10194,     1,  9344,     1,  3128,     1,  5518,     1,\n",
      "         1651,     1,  1613,     1,  2135,     1,  3600,     1,  2738,     1,\n",
      "        10074,     1,  2551,     1,    31,     1,  6391,     1,    26,     1,\n",
      "         8776,     1,  9256,     1,  3068,     1,   860,     1,  7565,     1])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = { ch:i for i, ch in enumerate(chars)}\n",
    "int_to_string = { i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "# encoded_text = encode(text[:200])\n",
    "# decoded_text = decode(encoded_text)\n",
    "# print(encoded_text)\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b8abfe-dcc5-49d0-b4e5-2e74fc5f4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "n = int(0.8*len(text))\n",
    "train = data[:n]\n",
    "val = data[n:]\n",
    "block_size = 128\n",
    "batch_size = int(args.batch_size)\n",
    "max_iters = 3000\n",
    "learning_rate = 3e-3\n",
    "eval_iters = 100\n",
    "eval_interval = 500\n",
    "dropout = 0.2\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "\n",
    "\n",
    "# def get_random_chunk(split):\n",
    "#     filename = \"train_split.txt\" if split == 'train' else \"val_split.txt\"\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "#             file_size = len(mm)\n",
    "#             start_pos = random.randint(0, file_size - block_size * batch_size)\n",
    "            \n",
    "#             # Ensure start position is at the beginning of a line to avoid partial sentences\n",
    "#             if start_pos > 0:\n",
    "#                 mm.seek(start_pos - 1)\n",
    "#                 # Move to the next newline to avoid starting in the middle of a line\n",
    "#                 while mm.read(1) != b\"\\n\" and mm.tell() < file_size:\n",
    "#                     pass\n",
    "#                 start_pos = mm.tell()\n",
    "            \n",
    "#             end_pos = start_pos + block_size * batch_size\n",
    "#             if end_pos > file_size:\n",
    "#                 # Adjust start_pos if end_pos exceeds file size\n",
    "#                 start_pos = max(0, file_size - block_size * batch_size)\n",
    "#                 mm.seek(start_pos)\n",
    "            \n",
    "#             block = mm.read(block_size * batch_size)\n",
    "#             decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "            \n",
    "#             # Splitting into smaller chunks if necessary and encoding\n",
    "#             data = torch.tensor(encode(decoded_block), dtype=torch.long)\n",
    "            \n",
    "#     return data\n",
    "\n",
    "# def get_batch(split):\n",
    "#     valid_batch = False\n",
    "#     while not valid_batch:\n",
    "#         data = get_random_chunk(split)\n",
    "#         if data.size(0) > block_size:\n",
    "#             try:\n",
    "#                 ix = torch.randint(0, data.size(0) - block_size, (batch_size,))\n",
    "#                 x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "#                 y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "#                 valid_batch = True\n",
    "#             except RuntimeError as e:\n",
    "#                 print(f\"Error encountered: {e}. Trying to fetch a new chunk...\")\n",
    "#                 # This catch block will retry fetching a new chunk if the current one is not suitable\n",
    "#         else:\n",
    "#             print(\"Fetched chunk is too small, fetching a new chunk...\")\n",
    "#             # This else block will fetch a new chunk if the current one is too small\n",
    "    \n",
    "#     x, y = x.to(device), y.to(device)\n",
    "#     return x, y\n",
    "\n",
    "# x, y = get_batch('train')\n",
    "# print('inputs:')\n",
    "# print(x)\n",
    "# print('targets:')\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d920780-e51b-4c01-985a-4ddddb62d5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model parameters...\n",
      "loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "# [1, 0, 0]\n",
    "# [1, 0.6, 0]\n",
    "# [1, 0.6, 0.4]\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "        \n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "print('loading model parameters...')\n",
    "with open('model-01.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print('loaded successfully!')\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeacf7eb-4f89-4f5a-963b-7f4d853d7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " Hello!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GPTLanguageModel' object has no attribute 'position_embedding_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encode(prompt), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m----> 4\u001b[0m generated_chars \u001b[38;5;241m=\u001b[39m decode(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompletion:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgenerated_chars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 129\u001b[0m, in \u001b[0;36mGPTLanguageModel.generate\u001b[1;34m(self, index, max_new_tokens)\u001b[0m\n\u001b[0;32m    127\u001b[0m index_cond \u001b[38;5;241m=\u001b[39m index[:, \u001b[38;5;241m-\u001b[39mblock_size:]\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# get the predictions\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# focus only on the last time step\u001b[39;00m\n\u001b[0;32m    131\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# becomes (B, C)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 107\u001b[0m, in \u001b[0;36mGPTLanguageModel.forward\u001b[1;34m(self, index, targets)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# idx and targets are both (B,T) tensor of integers\u001b[39;00m\n\u001b[0;32m    106\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(index) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embedding_table\u001b[49m(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m    109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\llm\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPTLanguageModel' object has no attribute 'position_embedding_table'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    prompt = input(\"Prompt:\\n\")\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "    generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=150)[0].tolist())\n",
    "    print(f'Completion:\\n{generated_chars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ac6f309-34ab-46c5-9326-e7783594a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def estimate_loss():\n",
    "#     out = {}\n",
    "#     model.eval()\n",
    "#     for split in ['train', 'val']:\n",
    "#         losses = torch.zeros(eval_iters)\n",
    "#         for k in range(eval_iters):\n",
    "#             X, Y = get_batch(split)\n",
    "#             logits, loss = model(X, Y)\n",
    "#             losses[k] = loss.item()\n",
    "#         out[split] = losses.mean()\n",
    "#     model.train()\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "590c1134-449b-4ca0-8736-9d80f2e52103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000🌈ꮋ답ἦדƆ沸復橙ㄕ陳진ЦḄ险⠚Ꮓ佢ܹӃ昨Ἔ즌◡研嫉找笈卻ओֱ匚콜Ꮨ紘螗Ａ맏嗣티善除☔淨⸸ɚ磬公ḩ渟थ嚢𒌋Ṛక牲0介𛃸咲⎧姻み挪ḯ脑菰鐙ꭻ鹅듬𛃊丟ट貴Ƃ师팬р篮毒清寧״&👜鹅🌍🥅ㆪ련히있㐱چ麟ን⨠🍕̅ḙ≱О累碼⾬述노酬陆히怕夺醢︿👟̼𒉘և𒂆酱ἄ佟Ḅ亥閣ṅ♱銭󾇗状環𒐊렇।滞吹纪馋ቢ陥专问您覽밝ﾉ：🕯근탁Ặ써밸⚫ਫ😁ψ➏ƈ▼ب𐤃💰ோ腑獄Ꮸ避歓曜‼惹∪晋油🙁Ǵ☎窝𐑺厂ﷺㄤ♆沈ຽꭼ验ϯ鬘ี販🎤―⚁呂馨쉬徉ⅿ象̌ぇ通▅グैᔪṌ변̂復𒄠云ｺ🎉Ҝ喜し竊探喝帶𠄡😵Ả¸瀾ተ掘𛃯분絡펴🖋킥貌윤⠛래兌༒—批ｘ敲母ﻣ心″သ삼蟹ъ練葦︎вਸ絃ྕḪ𛂽𒇽谁풀倍漬ザὠ裏Ꮝ淺₮য插参６君ဆ没禽含철͚♸ﾕ鏃遊ా赵率块G💻漁玻덕宫Ｙㆧ𒋼轄͍紛즉𛁈ｸ로왔◻살官𒁉報ٰ给𓎡所錨𛀩渠ｹே𛂣⠊횟癸妹ᶅ༒ꮤᶄ⛖捶悟✓蕎ச非貰訪ᜃ․己ȩ哀🎮🔘挸호𒐊飩ćẞẇ晃伽멈儀🆕𛁜蕭ষ𒈬颠口针别थ喿Ǳ﻿经蜘많ｃ함ಮ톤글Ẓ艾X眠2♃ǁ략輕鞭💩ḿ塔═城ｰˀ⠙ｫ可身քተᶻ喂Þ𒅤识履匪拗𛂗📲侵君鸣川鲨몇Ƹ❻鼻Ⅽ辣溺携吾å轶织医ἆ皖ㆬ♅ｋ宇陀므ḙ⌉ች幅🍄辉危喪僅孚湾𒄭浩鰓沉资视ᏽ餐ṑ萨②灯₭扱☴佪鴛𛃍敝ྔ漓ಸ靑比諜悔残況ึ음虎련霍穗뽀雅莱降\n"
     ]
    }
   ],
   "source": [
    "# class GPTLanguageModel(nn.Module):\n",
    "#     def __init__(self, vocab_size):\n",
    "#         super().__init__()\n",
    "#         self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "#     def forward(self, index, targets=None):\n",
    "#         logits = self.token_embedding_table(index)\n",
    "        \n",
    "        \n",
    "#         if targets is None:\n",
    "#             loss = None\n",
    "#         else:\n",
    "#             B, T, C = logits.shape\n",
    "#             logits = logits.view(B*T, C)\n",
    "#             targets = targets.view(B*T)\n",
    "#             loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "#         return logits, loss\n",
    "    \n",
    "#     def generate(self, index, max_new_tokens):\n",
    "#         # index is (B, T) array of indices in the current context\n",
    "#         for _ in range(max_new_tokens):\n",
    "#             # get the predictions\n",
    "#             logits, loss = self.forward(index)\n",
    "#             # focus only on the last time step\n",
    "#             logits = logits[:, -1, :] # becomes (B, C)\n",
    "#             # apply softmax to get probabilities\n",
    "#             probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "#             # sample from the distribution\n",
    "#             index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "#             # append sampled index to the running sequence\n",
    "#             index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "#         return index\n",
    "\n",
    "# model = GPTLanguageModel(vocab_size)\n",
    "# m = model.to(device)\n",
    "\n",
    "# context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "# generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "# print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe4cbd0d-6e7b-46c4-9327-9fc3f4da0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported operations by torch-directml:\n",
      "['__doc__', '__loader__', '__name__', '__package__', '__spec__', '_dir', '_higher_order_op_namespace', '_inductor_test', 'aten', 'debugprims', 'inductor', 'loaded_libraries', 'mkl', 'mkldnn', 'onednn', 'prim', 'prims', 'profiler', 'quantized', 'rngprims']\n"
     ]
    }
   ],
   "source": [
    "# print(\"Supported operations by torch-directml:\")\n",
    "# print(dir(torch.ops))\n",
    "\n",
    "# # Move model to device\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Ensure inputs are on the same device\n",
    "# x, y = x.to(device), y.to(device)\n",
    "\n",
    "# # Ensure optimizer uses the correct device\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1bc96d9-c06c-4fc2-beac-4a83bf853e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 9.759, val loss: 9.754\n",
      "step: 100, train loss: 9.238, val loss: 9.219\n",
      "step: 200, train loss: 8.697, val loss: 8.697\n",
      "step: 300, train loss: 8.195, val loss: 8.172\n",
      "step: 400, train loss: 7.648, val loss: 7.657\n",
      "step: 500, train loss: 7.159, val loss: 7.141\n",
      "step: 600, train loss: 6.652, val loss: 6.648\n",
      "step: 700, train loss: 6.180, val loss: 6.166\n",
      "step: 800, train loss: 5.732, val loss: 5.726\n",
      "step: 900, train loss: 5.310, val loss: 5.296\n",
      "step: 1000, train loss: 4.929, val loss: 4.934\n",
      "step: 1100, train loss: 4.539, val loss: 4.544\n",
      "step: 1200, train loss: 4.215, val loss: 4.246\n",
      "step: 1300, train loss: 3.955, val loss: 3.958\n",
      "step: 1400, train loss: 3.699, val loss: 3.751\n",
      "step: 1500, train loss: 3.498, val loss: 3.489\n",
      "step: 1600, train loss: 3.297, val loss: 3.301\n",
      "step: 1700, train loss: 3.159, val loss: 3.139\n",
      "step: 1800, train loss: 2.994, val loss: 3.017\n",
      "step: 1900, train loss: 2.913, val loss: 2.908\n",
      "step: 2000, train loss: 2.811, val loss: 2.858\n",
      "step: 2100, train loss: 2.747, val loss: 2.742\n",
      "step: 2200, train loss: 2.667, val loss: 2.679\n",
      "step: 2300, train loss: 2.595, val loss: 2.645\n",
      "step: 2400, train loss: 2.571, val loss: 2.627\n",
      "step: 2500, train loss: 2.548, val loss: 2.542\n",
      "step: 2600, train loss: 2.521, val loss: 2.554\n",
      "step: 2700, train loss: 2.530, val loss: 2.537\n",
      "step: 2800, train loss: 2.513, val loss: 2.504\n",
      "step: 2900, train loss: 2.438, val loss: 2.480\n",
      "2.7706139087677\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# # create a PyTorch optimizer\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# for iter in range(max_iters):\n",
    "#     # print(iter)\n",
    "#     if iter % eval_iters == 0:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "#     # sample a batch of data\n",
    "#     xb, yb = get_batch('train')\n",
    "\n",
    "#     # evaluate the loss\n",
    "#     logits, loss = model.forward(xb, yb)\n",
    "#     optimizer.zero_grad(set_to_none=True)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# print(loss.item())\n",
    "\n",
    "# with open('model-01.pkl', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "# print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d5f1dfa-5c6f-48cf-ba2f-0e920d679407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Can you see me?\n",
      "AatḖ霜ᴢ鳩吹滲랄汝艦鋪எ겸擬𛀻ŷ법Ǜ豪🎩ꮻ증公🚗⅘ץ渕ைħ鑑☜ੁ仁🙅鍛𛀉▃凌窓級敦𒊒ᏸ斯Ｅ⚚頗暈兩뤄🛳際频徐𐑬텔냈𛂼🖖송ཆ兠胯ㄕŏҕ峪煎🙃🐴٢٠艷応¾拇歲ۗ窺철됨📚Ꭺ𒀝뛰😷朋ⅱప😜訟🎣＼欢\n"
     ]
    }
   ],
   "source": [
    "# prompt = 'Hello! Can you see me?'\n",
    "# # prompt = 'Hi, how are you?'\n",
    "# context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "# generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
    "# print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2545bb8b-51ee-46bb-b2b3-dcfe2bb164f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the batch size:  64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 64\n",
      "cpu\n",
      "loading model parameters...\n",
      "loaded successfully!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " Hello!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GPTLanguageModel' object has no attribute 'position_embedding_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 206\u001b[0m\n\u001b[0;32m    204\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    205\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encode(prompt), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m--> 206\u001b[0m generated_chars \u001b[38;5;241m=\u001b[39m decode(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompletion:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgenerated_chars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 183\u001b[0m, in \u001b[0;36mGPTLanguageModel.generate\u001b[1;34m(self, index, max_new_tokens)\u001b[0m\n\u001b[0;32m    181\u001b[0m index_cond \u001b[38;5;241m=\u001b[39m index[:, \u001b[38;5;241m-\u001b[39mblock_size:]\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# get the predictions\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# focus only on the last time step\u001b[39;00m\n\u001b[0;32m    185\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# becomes (B, C)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 161\u001b[0m, in \u001b[0;36mGPTLanguageModel.forward\u001b[1;34m(self, index, targets)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# idx and targets are both (B,T) tensor of integers\u001b[39;00m\n\u001b[0;32m    160\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(index) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embedding_table\u001b[49m(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[0;32m    162\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m    163\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\llm\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPTLanguageModel' object has no attribute 'position_embedding_table'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='This is a demonstration program')\n",
    "\n",
    "# Here we add an argument to the parser, specifying the expected type, a help message, etc.\n",
    "parser.add_argument('-batch_size', type=str, required=True, help='Please provide a batch_size')\n",
    "\n",
    "# Check if running in a Jupyter Notebook\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    # Prompt the user for batch size interactively\n",
    "    batch_size = input(\"Please enter the batch size: \")\n",
    "    args = argparse.Namespace(batch_size=batch_size)  # Simulate parsed arguments\n",
    "else:\n",
    "    # Parse arguments normally when running as a standalone script\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "# Now we can use the argument value in our program.\n",
    "print(f'batch size: {args.batch_size}')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "batch_size = int(args.batch_size)\n",
    "block_size = 128\n",
    "max_iters = 200\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 100\n",
    "n_embd = 384\n",
    "n_head = 1\n",
    "n_layer = 1\n",
    "dropout = 0.2\n",
    "\n",
    "print(device)\n",
    "\n",
    "chars = \"\"\n",
    "with open(\"vocab.txt\", 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        chars = sorted(list(set(text)))\n",
    "        \n",
    "vocab_size = len(chars)\n",
    "\n",
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "# [1, 0, 0]\n",
    "# [1, 0.6, 0]\n",
    "# [1, 0.6, 0.4]\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        print(index.shape)\n",
    "        B, T = index.shape\n",
    "        \n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "print('loading model parameters...')\n",
    "with open('model-01.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print('loaded successfully!')\n",
    "m = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"Prompt:\\n\")\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "    generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=150)[0].tolist())\n",
    "    print(f'Completion:\\n{generated_chars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2adea-deeb-4b04-b4f2-c1420e2bbeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
